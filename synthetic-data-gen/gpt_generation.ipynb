{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## Homonym Generation using GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4QSLJxfg_YQ"
      },
      "outputs": [],
      "source": [
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "d0fR6D1Gpmf8",
        "outputId": "65d8a15c-2728-4e79-b475-c36f93607307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: 'OPENAI_API_KEY' not found in Colab secrets.\n",
            "OpenAI Client Initialized.\n",
            "\n",
            "--- Generating cluster for: balance ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2746003631.py:313: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  endings_a: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning A.\", min_items=2, max_items=2)\n",
            "/tmp/ipython-input-2746003631.py:313: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  endings_a: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning A.\", min_items=2, max_items=2)\n",
            "/tmp/ipython-input-2746003631.py:318: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  endings_b: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning B.\", min_items=2, max_items=2)\n",
            "/tmp/ipython-input-2746003631.py:318: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  endings_b: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning B.\", min_items=2, max_items=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'balance'.\n",
            "\n",
            "--- Generating cluster for: patch ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'patch'.\n",
            "\n",
            "--- Generating cluster for: protocol ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'protocol'.\n",
            "\n",
            "--- Generating cluster for: grave ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'grave'.\n",
            "\n",
            "--- Generating cluster for: nail ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'nail'.\n",
            "\n",
            "--- Generating cluster for: produce ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'produce'.\n",
            "\n",
            "--- Generating cluster for: address ---\n",
            "   Successfully generated 8 entries (6 required + 2 secondary consistent) for 'address'.\n",
            "\n",
            "✅ Final Count: 56 entries generated (8 entries per word).\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_78c96e0a-d7a8-4bb4-ba67-7f637058c934\", \"wsd_generated_gpt_full_adversarial.json\", 31337)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title WSD Data Generator (Adversarial Cross-Combination Logic)\n",
        "# @title 1. Setup and Imports\n",
        "!pip install openai pydantic --quiet\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from google.colab import userdata, files\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- AUTHENTICATION ---\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "    # Fallback for local testing, though Colab secrets are highly recommended.\n",
        "    print(\"WARNING: 'OPENAI_API_KEY' not found in Colab secrets.\")\n",
        "    # For a persistent run, ensure your key is set here or in secrets.\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"OpenAI Client Initialized.\")\n",
        "\n",
        "# --- 2. GENERATION SCHEMA (Internal) ---\n",
        "# This schema forces GPT to generate the full \"Cluster\" of data points in one call.\n",
        "class ScenarioCluster(BaseModel):\n",
        "    homonym: str\n",
        "    precontext: str = Field(..., description=\"The setup text (2-3 sentences) that is valid for BOTH meanings.\")\n",
        "    sentence: str = Field(..., description=\"The ambiguous pivot sentence containing the homonym.\")\n",
        "\n",
        "    # Meaning A\n",
        "    judged_meaning_a: str = Field(..., description=\"The definition of the first meaning.\")\n",
        "    endings_a: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning A.\", min_items=2, max_items=2)\n",
        "    example_a: str = Field(..., description=\"A simple, unambiguous example sentence for Meaning A.\")\n",
        "\n",
        "    # Meaning B\n",
        "    judged_meaning_b: str = Field(..., description=\"The definition of the second meaning.\")\n",
        "    endings_b: List[str] = Field(..., description=\"Generate exactly 2 different endings that resolve to Meaning B.\", min_items=2, max_items=2)\n",
        "    example_b: str = Field(..., description=\"A simple, unambiguous example sentence for Meaning B.\")\n",
        "\n",
        "class GenerationResponse(BaseModel):\n",
        "    clusters: List[ScenarioCluster]\n",
        "\n",
        "# --- 3. OUTPUT SCHEMA (Final List Item) ---\n",
        "# This is the strict format for each entry in the final JSON list.\n",
        "class WSDItem(BaseModel):\n",
        "    homonym: str\n",
        "    judged_meaning: str\n",
        "    precontext: str\n",
        "    sentence: str\n",
        "    ending: str\n",
        "    example_sentence: str\n",
        "\n",
        "# --- 4. PIPELINE ---\n",
        "\n",
        "def generate_wsd_dataset(homonyms_list: List[dict]):\n",
        "    final_entries = []\n",
        "\n",
        "    # Helper function for appending entries\n",
        "    def append_entry(cluster, meaning, ending, example):\n",
        "        return WSDItem(\n",
        "            homonym=cluster.homonym,\n",
        "            judged_meaning=meaning,\n",
        "            precontext=cluster.precontext,\n",
        "            sentence=cluster.sentence,\n",
        "            ending=ending,\n",
        "            example_sentence=example\n",
        "        ).model_dump()\n",
        "\n",
        "    for item in homonyms_list:\n",
        "        word = item['word']\n",
        "        print(f\"\\n--- Generating cluster for: {word} ---\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "See this example of how ambiguous sentences work (note how 'precontext' and 'sentence' stay the same, but the 'judged_meaning' and 'ending' change):\n",
        "\n",
        "{{\n",
        "    \"1\": {{\n",
        "        \"homonym\": \"bugs\",\n",
        "        \"judged_meaning\": \"general term for any insect\",\n",
        "        \"precontext\": \"Anna was having a tough week. Her room was a mess, and her computer kept crashing. Frustrated by everything going wrong, she called Jen.\",\n",
        "        \"sentence\": \"She asked her friend to help her get rid of the bugs.\",\n",
        "        \"ending\": \"They were crawling on the keyboard. Maybe that was the reason it didn't work.\",\n",
        "        \"example_sentence\": \"The garden was full of bugs.\"\n",
        "    }},\n",
        "    \"2\": {{\n",
        "        \"homonym\": \"bugs\",\n",
        "        \"judged_meaning\": \"a fault or defect in a computer program\",\n",
        "        \"precontext\": \"Anna was having a tough week. Her room was a mess, and her computer kept crashing. Frustrated by everything going wrong, she called Jen.\",\n",
        "        \"sentence\": \"She asked her friend to help her get rid of the bugs.\",\n",
        "        \"ending\": \"They were crawling on the keyboard. Maybe that was the reason it didn't work.\",\n",
        "        \"example_sentence\": \"There's a bug in the software.\"\n",
        "    }}\n",
        "}}\n",
        "\n",
        "In a similar way, Generate a WSD Scenario Cluster for the homonym \"{word}\".\n",
        "\n",
        "Target Meanings:\n",
        "1. {item['meaning_a']}\n",
        "2. {item['meaning_b']}\n",
        "\n",
        "Requirements:\n",
        "- Write ONE 'precontext' and ONE 'sentence' that should be ambiguously applicable and meaningful for BOTH meanings.\n",
        "- The 'sentence' must be the ambiguous pivot.\n",
        "- Provide 2 distinct 'endings' that resolve to Meaning 1.\n",
        "- Provide 2 distinct 'endings' that resolve to Meaning 2.\n",
        "- Provide a simple 'example_sentence' for each meaning.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            completion = client.beta.chat.completions.parse(\n",
        "                model=\"gpt-4o-2024-08-06\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert NLP dataset generator. Generate a JSON object strictly following the ScenarioCluster schema.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "                response_format=GenerationResponse,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            cluster = completion.choices[0].message.parsed.clusters[0]\n",
        "\n",
        "            # --- ADVERSARIAL EXPANSION LOGIC ---\n",
        "\n",
        "            # Core Components:\n",
        "            W1_def = cluster.judged_meaning_a\n",
        "            W2_def = cluster.judged_meaning_b\n",
        "            E1_ending = cluster.endings_a[0] # The primary ending for W1\n",
        "            E2_ending = cluster.endings_b[0] # The primary ending for W2\n",
        "            EX1 = cluster.example_a\n",
        "            EX2 = cluster.example_b\n",
        "\n",
        "            # 1. W1 + E1 (Consistent)\n",
        "            final_entries.append(append_entry(cluster, W1_def, E1_ending, EX1))\n",
        "\n",
        "            # 2. W1 + E2 (Inconsistent/Adversarial: Judged Meaning A with Ending for B)\n",
        "            final_entries.append(append_entry(cluster, W1_def, E2_ending, EX1))\n",
        "\n",
        "            # 3. W2 + E2 (Consistent)\n",
        "            final_entries.append(append_entry(cluster, W2_def, E2_ending, EX2))\n",
        "\n",
        "            # 4. W2 + E1 (Inconsistent/Adversarial: Judged Meaning B with Ending for A)\n",
        "            final_entries.append(append_entry(cluster, W2_def, E1_ending, EX2))\n",
        "\n",
        "            # 5. W1 + Blank\n",
        "            final_entries.append(append_entry(cluster, W1_def, \"\", EX1))\n",
        "\n",
        "            # 6. W2 + Blank\n",
        "            final_entries.append(append_entry(cluster, W2_def, \"\", EX2))\n",
        "\n",
        "            # Add the secondary endings as additional, separate consistent examples\n",
        "            final_entries.append(append_entry(cluster, W1_def, cluster.endings_a[1], EX1))\n",
        "            final_entries.append(append_entry(cluster, W2_def, cluster.endings_b[1], EX2))\n",
        "\n",
        "            print(f\"   Successfully generated 8 entries (6 required + 2 secondary consistent) for '{word}'.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating {word}: {e}\")\n",
        "\n",
        "    return {\"entries\": final_entries}\n",
        "\n",
        "# --- 5. EXECUTION ---\n",
        "\n",
        "# Target homonyms using the comprehensive list\n",
        "target_homonyms_list = [\n",
        "    {\n",
        "        \"word\": \"balance\",\n",
        "        \"meaning_a\": \"The difference between assets and liabilities (Finance)\",\n",
        "        \"meaning_b\": \"A state of equilibrium; stability (Physical/General)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"patch\",\n",
        "        \"meaning_a\": \"A temporary code fix or software update (Technology)\",\n",
        "        \"meaning_b\": \"A small piece of material used to mend a hole (Physical/Layperson)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"protocol\",\n",
        "        \"meaning_a\": \"A set of rules governing data transmission (Networking)\",\n",
        "        \"meaning_b\": \"A formal procedure or set of etiquette rules (Diplomacy/General)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"grave\",\n",
        "        \"meaning_a\": \"An excavation site for burying a body (Literal)\",\n",
        "        \"meaning_b\": \"Serious, somber, or important (Metaphorical)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"nail\",\n",
        "        \"meaning_a\": \"A small metal spike driven into wood (Literal)\",\n",
        "        \"meaning_b\": \"To execute a task perfectly (Idiomatic)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"produce\",\n",
        "        \"meaning_a\": \"Fresh fruits and vegetables (Noun)\",\n",
        "        \"meaning_b\": \"To create or manufacture something (Verb)\"\n",
        "    },\n",
        "    {\n",
        "        \"word\": \"address\",\n",
        "        \"meaning_a\": \"A location or coordinates (Noun)\",\n",
        "        \"meaning_b\": \"To speak to or deal with a problem (Verb)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run generation\n",
        "dataset = generate_wsd_dataset(target_homonyms_list)\n",
        "\n",
        "# --- 6. SAVE AND DOWNLOAD ---\n",
        "\n",
        "output_filename = 'wsd_generated_gpt_full_adversarial.json'\n",
        "with open(output_filename, 'w') as f:\n",
        "    json.dump(dataset, f, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Final Count: {len(dataset['entries'])} entries generated (8 entries per word).\")\n",
        "files.download(output_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
