{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_handwritten-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_builtin-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nbstripout in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.8.2)\n",
      "Requirement already satisfied: nbformat in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbstripout) (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.9.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.30.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nbstripout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout base_data_SFT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert base_dataset_SFT.ipynb \\\n",
    "  --to notebook \\\n",
    "  --execute \\\n",
    "  --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MbZA3ljIM9Z",
    "outputId": "4f340066-f83a-42e0-bf70-40c2ea040bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "11f2b797983b4fefa36c403b5e0c9d6f",
      "614b9d24b3b54139918f2aff4955c524",
      "8c7fe35d32ca4a94a91eb3751d0d62d7",
      "e0f87c4eb6a64a948242fcd569b689ee",
      "f572cd0efbc24d0da44ad233c407d315",
      "20e248263b38407baad095418ee93e90",
      "1647b2ef04d643519b5c63c288d92129",
      "95b6f74e4cf54230be1c3343d541c310",
      "529dca5f21a0447a9474f26ecbfbe756",
      "bc3d2d70b1a842418a5ee7c5cd40a0ac",
      "1f4b2301505b4d498253fc7e76cdd9ec",
      "2213eeb6c61f40018b6b1ed87ab03016",
      "0cff88f14122424ab535536230f76825",
      "f6bcf6793d63495c8a58bd927682c06c",
      "fea2cc8f844e4eaba5a615fb980d25a5",
      "b5c47925f2fc4391a3376a4f5b8080ca",
      "4956d699c99044bcb3b123358b351cdb",
      "4b9e60e9f6e64ea6a218eb7d2bf14101",
      "1c0f25cc32374842bd01b0c30c457fbd",
      "845fe5f3dc1a44a1bb527444bea5df28",
      "aa4b8fe89b0a411592baabffeb5d6bdd",
      "75d8cb309df443a7a9e72095e9e12b12",
      "d902f10cd8a54e35bb7145ec43e71085",
      "67090763fbd347bda2f46c2f8967c940",
      "ad89e5aaefe94ca0821d8927566da424",
      "b851794d973a47e6b9310dea9dcfb8b9",
      "58f0e11182e44b2da6762fc4293b827c",
      "239fab3438e545c59f8ee7ea509c1619",
      "3982d1b31f144e3aa502ead4f9f0cb96",
      "f48a36286be84813a611eebf4d5338a1",
      "f1479ba791bc458ea8cc795dfba80290",
      "0a8e9e8a5d804263b93122d465dc517a",
      "d72c2172d5654d4783a2f7ff2af5c8d7",
      "ff87cbfde7d0402b87f75099bb9e027f",
      "b3eef05f491847959b4f46c5194d6b2a",
      "b6a12ce2b91c48519c72f57006819fa7",
      "5b5149d918224eaf8bf538a9b0aaf264",
      "d40729669d574706835a331c146d5eca",
      "2eea6169bce84feb891414377fb5b8d6",
      "ff9d30fe0ee545848823137b22e5d42c",
      "d1c1579010774de4933422d25814a70d",
      "472c356556b542dd8afc9a3c16914562",
      "26f4ced73e50457e803e63c1696a2592",
      "2d337a043d08472fbceaee696928af04",
      "22b6ce38bee34c9a918119075fdacfd9",
      "3f26e1afa04b4ee1a81a8e960a6befbd",
      "09ca88d749c34365a4f376726ea7718a",
      "63d8e088056343e0be5db483f644a733",
      "9a64fe56e09c490193d1dc9a0365e1d3",
      "98c3a2f949e641ecaed71c32d07d48e9",
      "b0003d9633184b7aba4f70adc72c4896",
      "7b519445e9f64e59aa6ebfa7fda628d3",
      "80ce6cf8e1fc48b7aec3bf4bed9c79b3",
      "71984a24d6ef4a0cb4380ef20338f6bf",
      "b00c6a2dd2f3411994110c17d962f53f",
      "23964986fa7e473ca0ec045b506ce8e1",
      "c771b3b540a0423c9170008355ff026f",
      "073f1f789f364e158cf453bf50543f9a",
      "ef39b7a589044d9aafe3c8beb200ca10",
      "07d8e4e6ebe249dfaff581f76a9d8df2",
      "06ce72eba1014ec0b25499e6f6ed8c46",
      "214c171edd594fa88886d9a644a552bb",
      "d860bea6ab254935bd661b9dc9d89093",
      "a2fc9af005cf418f81791a9b9fcf8e12",
      "0e0ce02ca38449ffbf7cc6bede46b6cb",
      "472c4b3c10df4fff9d48d9411005763c",
      "58486f4ab9714559bab8577a264a9a32",
      "4ffec066355a47d8ac2462a19631878e",
      "932fae3621b748e1b34ad5217eddaba8",
      "bd410f10e6274d66a499cf1894675f28",
      "235afe6461ae45e181e15c839beb6de0",
      "49df422de065407cb8b91ab4885cd3a8",
      "ca315304191a47d4b02c128791914679",
      "ade5258b10084f97a422400e59e1c36b",
      "5cef054488ed4c688994d480b7fd2f65",
      "eb53997cb2cf40328b485873e1d4b814",
      "82f8eecf1b594b9888a17e0a2f06cec9",
      "1a9a6c41199448eb8999a4eaedd1a929",
      "ec8fbb3cbaf84cef973635193ac83661",
      "dd35c7d771544e70a58bb3634ea91899",
      "4d18e5c3485c4b03a0943ca69297eeab",
      "e08f767dcf8145e68456ec1aabf34da8",
      "2174e3e2e78f4278ba6b6106d71ce36a",
      "e984cd98ef7040edba4b106a56232350",
      "235ff879c67047d9b70356d9ecb27f7a",
      "407d26ca57874972a67c525df7b3e57c",
      "6c9eff76bd254506878c48feab495cd9",
      "4d15a474ce9a4be68c7ef622cb08ae32",
      "626b6d4f54784eccbdc3fdabfa876e86",
      "8ae278e7e0cf46078cb4227df9977743",
      "438916b78ab3457fa870ada5fca67909",
      "0eb53418c5d64a279e2e8a6cc955f5fb",
      "84daa64914884877bd3ab2304033b830",
      "c370f73c042645e68aff0df85002e420",
      "9a2f627f381c4da69ed9c0806608afda",
      "86ba977b8d4f42b2af9a80f90631bd1c",
      "e77c51045a5d49d99f944e32afeb8e5c",
      "c367adcf8ac4429a897cc41dba8963cb",
      "389fb8f85c104a4fa0a0a232d602e06a"
     ]
    },
    "id": "RYM2J9A2bhS1",
    "outputId": "528c6198-c92a-4c4b-aa3c-24929f80a93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Gold Train: 2280\n",
      "Loaded Gold Dev:   588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f2b797983b4fefa36c403b5e0c9d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2213eeb6c61f40018b6b1ed87ab03016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902f10cd8a54e35bb7145ec43e71085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff87cbfde7d0402b87f75099bb9e027f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b6ce38bee34c9a918119075fdacfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23964986fa7e473ca0ec045b506ce8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58486f4ab9714559bab8577a264a9a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9a6c41199448eb8999a4eaedd1a929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626b6d4f54784eccbdc3fdabfa876e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1395062482.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,359,680 || all params: 1,548,075,520 || trainable%: 0.2816\n",
      "Starting Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 28:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.225900</td>\n",
       "      <td>1.198675</td>\n",
       "      <td>0.566923</td>\n",
       "      <td>0.887466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.810500</td>\n",
       "      <td>1.503710</td>\n",
       "      <td>0.575893</td>\n",
       "      <td>0.973782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.731500</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.655452</td>\n",
       "      <td>0.746876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.529300</td>\n",
       "      <td>0.922254</td>\n",
       "      <td>0.661046</td>\n",
       "      <td>0.754241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.881218</td>\n",
       "      <td>0.675195</td>\n",
       "      <td>0.760740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.742854</td>\n",
       "      <td>0.710065</td>\n",
       "      <td>0.685618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.799104</td>\n",
       "      <td>0.693775</td>\n",
       "      <td>0.699293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.776403</td>\n",
       "      <td>0.719607</td>\n",
       "      <td>0.703798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.747626</td>\n",
       "      <td>0.727959</td>\n",
       "      <td>0.678250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.732521</td>\n",
       "      <td>0.652705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best adapter saved to /content/drive/MyDrive/nlp/Qwen_SFT_Gold_Synth_FullMetrics/best_adapter\n",
      "\n",
      "=== CLEANING MEMORY FOR INFERENCE ===\n",
      "Reloading Base Model + Best Adapter for Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1395062482.py:281: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  predictor = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on Test (Gold Dev) Set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "FINAL RESULTS (Gold + Synth SFT)\n",
      "========================================\n",
      "Global Spearman:       0.5970\n",
      "Macro Spearman:        0.5869\n",
      "MAE:                   0.7732\n",
      "Accuracy within Stdev: 0.6293\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "# hashing for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# paths\n",
    "GOLD_TRAIN_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "GOLD_DEV_PATH   = \"/content/drive/MyDrive/nlp/dev.json\"\n",
    "OUTPUT_DIR      = \"/content/drive/MyDrive/nlp/Qwen_SFT_Gold_Synth_FullMetrics\"\n",
    "\n",
    "# model configuration\n",
    "MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 384\n",
    "\n",
    "\n",
    "# data loading & preprocessing\n",
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "def flatten_records(records):\n",
    "    \"\"\"Safely flatten nested synthetic JSON lists.\"\"\"\n",
    "    flat = []\n",
    "    for r in records:\n",
    "        if isinstance(r, list):\n",
    "            flat.extend(flatten_records(r))\n",
    "        elif isinstance(r, dict):\n",
    "            flat.append(r)\n",
    "    return flat\n",
    "\n",
    "def build_examples_chat_format(records):\n",
    "    \"\"\"\n",
    "    Constructs input using Qwen's ChatML-like structure.\n",
    "    Also extracts metadata (group_id, stdev) for detailed metrics.\n",
    "    \"\"\"\n",
    "    ex = []\n",
    "    for r in records:\n",
    "        if not isinstance(r, dict): continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        ending = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        # Meta-data for final evaluation\n",
    "        homonym = (r.get(\"homonym\") or \"\").strip()\n",
    "        # Group ID: Used for Macro-Spearman grouping by unique context\n",
    "        gid = f\"{homonym}||{pre}||{sent}\"\n",
    "\n",
    "        # build story text\n",
    "        story_text = f\"{pre} {sent}\"\n",
    "        if ending:\n",
    "            story_text += f\" {ending}\"\n",
    "\n",
    "        # structure as an instruction\n",
    "        prompt = (\n",
    "            f\"<|im_start|>system\\n\"\n",
    "            f\"You are a semantic judge. Rate the plausibility of the Definition given the Story.<|im_end|>\\n\"\n",
    "            f\"<|im_start|>user\\n\"\n",
    "            f\"Story: {story_text}\\n\"\n",
    "            f\"Definition: {meaning}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "            f\"Plausibility Score:\"\n",
    "        )\n",
    "\n",
    "        avg = float(r.get(\"average\", 0.0))\n",
    "        stdev = float(r.get(\"stdev\", 0.0))\n",
    "\n",
    "        ex.append({\n",
    "            \"text\": prompt,\n",
    "            \"label\": avg,\n",
    "            \"stdev\": stdev,\n",
    "            \"group_id\": gid\n",
    "        })\n",
    "    return ex\n",
    "\n",
    "# Load Data\n",
    "gold_train_records = load_json_records(GOLD_TRAIN_PATH)\n",
    "gold_dev_records   = load_json_records(GOLD_DEV_PATH)\n",
    "\n",
    "\n",
    "print(f\"Loaded Gold Train: {len(gold_train_records)}\")\n",
    "print(f\"Loaded Gold Dev:   {len(gold_dev_records)}\")\n",
    "\n",
    "# Build Examples\n",
    "gold_train_ex = build_examples_chat_format(gold_train_records)\n",
    "gold_dev_ex   = build_examples_chat_format(gold_dev_records)\n",
    "\n",
    "\n",
    "train_full_ex = gold_train_ex\n",
    "train_df_full = pd.DataFrame(train_full_ex)\n",
    "dev_df        = pd.DataFrame(gold_dev_ex) # separate for testing\n",
    "\n",
    "# 80/20 split of train data\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# print(f\"Training Set Size:   {len(train_df)}\")\n",
    "# print(f\"Validation Set Size: {len(val_df)}\")\n",
    "# print(f\"Test Set (Gold Dev): {len(dev_df)}\")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})\n",
    "\n",
    "# tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# only torch columns for training\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "tokenized.set_format(type=\"torch\", columns=cols_to_keep)\n",
    "\n",
    "# model setup (LoRA + Regression Head)\n",
    "\n",
    "print(\"Loading Model...\")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    modules_to_save=[\"score\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "# training metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr) if not np.isnan(spearman_corr) else 0.0,\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "# training\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.05,\n",
    "    fp16=True,\n",
    "\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "trainer.train()\n",
    "\n",
    "# saving adapter\n",
    "adapter_path = os.path.join(OUTPUT_DIR, \"best_adapter\")\n",
    "trainer.save_model(adapter_path)\n",
    "print(f\"Best adapter saved to {adapter_path}\")\n",
    "\n",
    "\n",
    "# inference and  evaluation\n",
    "print(\"\\n=== CLEANING MEMORY FOR INFERENCE ===\")\n",
    "del model, base_model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"Reloading Base Model + Best Adapter for Inference...\")\n",
    "\n",
    "inference_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "inference_base.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "inference_model = PeftModel.from_pretrained(inference_base, adapter_path)\n",
    "inference_model.eval()\n",
    "\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=os.path.join(OUTPUT_DIR, \"eval_temp\"),\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "predictor = Trainer(\n",
    "    model=inference_model,\n",
    "    args=eval_args,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"Predicting on Test (Gold Dev) Set...\")\n",
    "pred_output = predictor.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred_output.predictions), 1.0, 5.0)\n",
    "\n",
    "# metrics calculations\n",
    "# Retrieve True Labels and Metadata from the dataframe\n",
    "# (Order is preserved by the Trainer)\n",
    "y_true = dev_df[\"label\"].to_numpy(float)\n",
    "y_stdev = dev_df[\"stdev\"].to_numpy(float)\n",
    "groups = dev_df[\"group_id\"].tolist()\n",
    "\n",
    "# Global Spearman & MAE\n",
    "global_spearman = spearmanr(y_true, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(y_true - raw_preds))\n",
    "\n",
    "# Accuracy within Std Dev\n",
    "errors = np.abs(raw_preds - y_true)\n",
    "within_stdev = errors <= y_stdev\n",
    "acc_stdev = float(np.mean(within_stdev))\n",
    "\n",
    "# Macro-Spearman\n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_corrs = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = y_true[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "    # variance to calculate correlation\n",
    "    if len(set(g_true)) > 1:\n",
    "        corr = spearmanr(g_true, g_pred).correlation\n",
    "        if not np.isnan(corr):\n",
    "            group_corrs.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_corrs)) if group_corrs else 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL RESULTS (Gold + Synth SFT)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within Stdev: {acc_stdev:.4f}\")\n",
    "print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0G-FztG85mB",
    "outputId": "50d747d5-3cc6-491b-b1e2-779cb6d62dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOOTSTRAP RESULTS (TEST SET)\n",
      "Global Spearman     : 0.5970 [0.5367, 0.6471]\n",
      "Macro Spearman      : 0.5446 [0.4485, 0.6284]\n",
      "MAE                 : 0.7730 [0.7303, 0.8206]\n",
      "Acc w/in Stdev      : 0.6287 [0.5884, 0.6667]\n"
     ]
    }
   ],
   "source": [
    "# bootstrapping\n",
    "def bootstrap_full_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    res_global_sps = []\n",
    "    res_macro_sps = []\n",
    "    res_maes = []\n",
    "    res_accs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # Global Spearman\n",
    "        gs = spearmanr(bt_true, bt_pred).correlation\n",
    "        res_global_sps.append(gs if not np.isnan(gs) else 0.0)\n",
    "\n",
    "        # MAE\n",
    "        res_maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # Accuracy within Stdev\n",
    "        res_accs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # Macro Spearman\n",
    "        # Re-group based on resampled data\n",
    "        local_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_map[g].append(i)\n",
    "\n",
    "        local_corrs = []\n",
    "        for g, g_idxs in local_map.items():\n",
    "            gt = bt_true[g_idxs]\n",
    "            gp = bt_pred[g_idxs]\n",
    "            if len(set(gt)) > 1:\n",
    "                c = spearmanr(gt, gp).correlation\n",
    "                if not np.isnan(c):\n",
    "                    local_corrs.append(c)\n",
    "\n",
    "        if local_corrs:\n",
    "            res_macro_sps.append(np.mean(local_corrs))\n",
    "        else:\n",
    "            res_macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"Global Spearman\": summarize(res_global_sps),\n",
    "        \"Macro Spearman\": summarize(res_macro_sps),\n",
    "        \"MAE\": summarize(res_maes),\n",
    "        \"Acc w/in Stdev\": summarize(res_accs),\n",
    "    }\n",
    "\n",
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "bootstrap_stats = bootstrap_full_metrics(\n",
    "    y_true=y_true,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=y_stdev,\n",
    "    groups=groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_stats.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}