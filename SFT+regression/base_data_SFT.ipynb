{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MbZA3ljIM9Z",
    "outputId": "4f340066-f83a-42e0-bf70-40c2ea040bee"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "11f2b797983b4fefa36c403b5e0c9d6f",
      "614b9d24b3b54139918f2aff4955c524",
      "8c7fe35d32ca4a94a91eb3751d0d62d7",
      "e0f87c4eb6a64a948242fcd569b689ee",
      "f572cd0efbc24d0da44ad233c407d315",
      "20e248263b38407baad095418ee93e90",
      "1647b2ef04d643519b5c63c288d92129",
      "95b6f74e4cf54230be1c3343d541c310",
      "529dca5f21a0447a9474f26ecbfbe756",
      "bc3d2d70b1a842418a5ee7c5cd40a0ac",
      "1f4b2301505b4d498253fc7e76cdd9ec",
      "2213eeb6c61f40018b6b1ed87ab03016",
      "0cff88f14122424ab535536230f76825",
      "f6bcf6793d63495c8a58bd927682c06c",
      "fea2cc8f844e4eaba5a615fb980d25a5",
      "b5c47925f2fc4391a3376a4f5b8080ca",
      "4956d699c99044bcb3b123358b351cdb",
      "4b9e60e9f6e64ea6a218eb7d2bf14101",
      "1c0f25cc32374842bd01b0c30c457fbd",
      "845fe5f3dc1a44a1bb527444bea5df28",
      "aa4b8fe89b0a411592baabffeb5d6bdd",
      "75d8cb309df443a7a9e72095e9e12b12",
      "d902f10cd8a54e35bb7145ec43e71085",
      "67090763fbd347bda2f46c2f8967c940",
      "ad89e5aaefe94ca0821d8927566da424",
      "b851794d973a47e6b9310dea9dcfb8b9",
      "58f0e11182e44b2da6762fc4293b827c",
      "239fab3438e545c59f8ee7ea509c1619",
      "3982d1b31f144e3aa502ead4f9f0cb96",
      "f48a36286be84813a611eebf4d5338a1",
      "f1479ba791bc458ea8cc795dfba80290",
      "0a8e9e8a5d804263b93122d465dc517a",
      "d72c2172d5654d4783a2f7ff2af5c8d7",
      "ff87cbfde7d0402b87f75099bb9e027f",
      "b3eef05f491847959b4f46c5194d6b2a",
      "b6a12ce2b91c48519c72f57006819fa7",
      "5b5149d918224eaf8bf538a9b0aaf264",
      "d40729669d574706835a331c146d5eca",
      "2eea6169bce84feb891414377fb5b8d6",
      "ff9d30fe0ee545848823137b22e5d42c",
      "d1c1579010774de4933422d25814a70d",
      "472c356556b542dd8afc9a3c16914562",
      "26f4ced73e50457e803e63c1696a2592",
      "2d337a043d08472fbceaee696928af04",
      "22b6ce38bee34c9a918119075fdacfd9",
      "3f26e1afa04b4ee1a81a8e960a6befbd",
      "09ca88d749c34365a4f376726ea7718a",
      "63d8e088056343e0be5db483f644a733",
      "9a64fe56e09c490193d1dc9a0365e1d3",
      "98c3a2f949e641ecaed71c32d07d48e9",
      "b0003d9633184b7aba4f70adc72c4896",
      "7b519445e9f64e59aa6ebfa7fda628d3",
      "80ce6cf8e1fc48b7aec3bf4bed9c79b3",
      "71984a24d6ef4a0cb4380ef20338f6bf",
      "b00c6a2dd2f3411994110c17d962f53f",
      "23964986fa7e473ca0ec045b506ce8e1",
      "c771b3b540a0423c9170008355ff026f",
      "073f1f789f364e158cf453bf50543f9a",
      "ef39b7a589044d9aafe3c8beb200ca10",
      "07d8e4e6ebe249dfaff581f76a9d8df2",
      "06ce72eba1014ec0b25499e6f6ed8c46",
      "214c171edd594fa88886d9a644a552bb",
      "d860bea6ab254935bd661b9dc9d89093",
      "a2fc9af005cf418f81791a9b9fcf8e12",
      "0e0ce02ca38449ffbf7cc6bede46b6cb",
      "472c4b3c10df4fff9d48d9411005763c",
      "58486f4ab9714559bab8577a264a9a32",
      "4ffec066355a47d8ac2462a19631878e",
      "932fae3621b748e1b34ad5217eddaba8",
      "bd410f10e6274d66a499cf1894675f28",
      "235afe6461ae45e181e15c839beb6de0",
      "49df422de065407cb8b91ab4885cd3a8",
      "ca315304191a47d4b02c128791914679",
      "ade5258b10084f97a422400e59e1c36b",
      "5cef054488ed4c688994d480b7fd2f65",
      "eb53997cb2cf40328b485873e1d4b814",
      "82f8eecf1b594b9888a17e0a2f06cec9",
      "1a9a6c41199448eb8999a4eaedd1a929",
      "ec8fbb3cbaf84cef973635193ac83661",
      "dd35c7d771544e70a58bb3634ea91899",
      "4d18e5c3485c4b03a0943ca69297eeab",
      "e08f767dcf8145e68456ec1aabf34da8",
      "2174e3e2e78f4278ba6b6106d71ce36a",
      "e984cd98ef7040edba4b106a56232350",
      "235ff879c67047d9b70356d9ecb27f7a",
      "407d26ca57874972a67c525df7b3e57c",
      "6c9eff76bd254506878c48feab495cd9",
      "4d15a474ce9a4be68c7ef622cb08ae32",
      "626b6d4f54784eccbdc3fdabfa876e86",
      "8ae278e7e0cf46078cb4227df9977743",
      "438916b78ab3457fa870ada5fca67909",
      "0eb53418c5d64a279e2e8a6cc955f5fb",
      "84daa64914884877bd3ab2304033b830",
      "c370f73c042645e68aff0df85002e420",
      "9a2f627f381c4da69ed9c0806608afda",
      "86ba977b8d4f42b2af9a80f90631bd1c",
      "e77c51045a5d49d99f944e32afeb8e5c",
      "c367adcf8ac4429a897cc41dba8963cb",
      "389fb8f85c104a4fa0a0a232d602e06a"
     ]
    },
    "id": "RYM2J9A2bhS1",
    "outputId": "528c6198-c92a-4c4b-aa3c-24929f80a93f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "# hashing for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# paths\n",
    "GOLD_TRAIN_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "GOLD_DEV_PATH   = \"/content/drive/MyDrive/nlp/dev.json\"\n",
    "OUTPUT_DIR      = \"/content/drive/MyDrive/nlp/Qwen_SFT_Gold_Synth_FullMetrics\"\n",
    "\n",
    "# model configuration\n",
    "MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 384\n",
    "\n",
    "\n",
    "# data loading & preprocessing\n",
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "def flatten_records(records):\n",
    "    \"\"\"Safely flatten nested synthetic JSON lists.\"\"\"\n",
    "    flat = []\n",
    "    for r in records:\n",
    "        if isinstance(r, list):\n",
    "            flat.extend(flatten_records(r))\n",
    "        elif isinstance(r, dict):\n",
    "            flat.append(r)\n",
    "    return flat\n",
    "\n",
    "def build_examples_chat_format(records):\n",
    "    \"\"\"\n",
    "    Constructs input using Qwen's ChatML-like structure.\n",
    "    Also extracts metadata (group_id, stdev) for detailed metrics.\n",
    "    \"\"\"\n",
    "    ex = []\n",
    "    for r in records:\n",
    "        if not isinstance(r, dict): continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        ending = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        # Meta-data for final evaluation\n",
    "        homonym = (r.get(\"homonym\") or \"\").strip()\n",
    "        # Group ID: Used for Macro-Spearman grouping by unique context\n",
    "        gid = f\"{homonym}||{pre}||{sent}\"\n",
    "\n",
    "        # build story text\n",
    "        story_text = f\"{pre} {sent}\"\n",
    "        if ending:\n",
    "            story_text += f\" {ending}\"\n",
    "\n",
    "        # structure as an instruction\n",
    "        prompt = (\n",
    "            f\"<|im_start|>system\\n\"\n",
    "            f\"You are a semantic judge. Rate the plausibility of the Definition given the Story.<|im_end|>\\n\"\n",
    "            f\"<|im_start|>user\\n\"\n",
    "            f\"Story: {story_text}\\n\"\n",
    "            f\"Definition: {meaning}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "            f\"Plausibility Score:\"\n",
    "        )\n",
    "\n",
    "        avg = float(r.get(\"average\", 0.0))\n",
    "        stdev = float(r.get(\"stdev\", 0.0))\n",
    "\n",
    "        ex.append({\n",
    "            \"text\": prompt,\n",
    "            \"label\": avg,\n",
    "            \"stdev\": stdev,\n",
    "            \"group_id\": gid\n",
    "        })\n",
    "    return ex\n",
    "\n",
    "# Load Data\n",
    "gold_train_records = load_json_records(GOLD_TRAIN_PATH)\n",
    "gold_dev_records   = load_json_records(GOLD_DEV_PATH)\n",
    "\n",
    "\n",
    "print(f\"Loaded Gold Train: {len(gold_train_records)}\")\n",
    "print(f\"Loaded Gold Dev:   {len(gold_dev_records)}\")\n",
    "\n",
    "# Build Examples\n",
    "gold_train_ex = build_examples_chat_format(gold_train_records)\n",
    "gold_dev_ex   = build_examples_chat_format(gold_dev_records)\n",
    "\n",
    "\n",
    "train_full_ex = gold_train_ex\n",
    "train_df_full = pd.DataFrame(train_full_ex)\n",
    "dev_df        = pd.DataFrame(gold_dev_ex) # separate for testing\n",
    "\n",
    "# 80/20 split of train data\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# print(f\"Training Set Size:   {len(train_df)}\")\n",
    "# print(f\"Validation Set Size: {len(val_df)}\")\n",
    "# print(f\"Test Set (Gold Dev): {len(dev_df)}\")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})\n",
    "\n",
    "# tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# only torch columns for training\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "tokenized.set_format(type=\"torch\", columns=cols_to_keep)\n",
    "\n",
    "# model setup (LoRA + Regression Head)\n",
    "\n",
    "print(\"Loading Model...\")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    modules_to_save=[\"score\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "# training metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr) if not np.isnan(spearman_corr) else 0.0,\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "# training\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.05,\n",
    "    fp16=True,\n",
    "\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "trainer.train()\n",
    "\n",
    "# saving adapter\n",
    "adapter_path = os.path.join(OUTPUT_DIR, \"best_adapter\")\n",
    "trainer.save_model(adapter_path)\n",
    "print(f\"Best adapter saved to {adapter_path}\")\n",
    "\n",
    "\n",
    "# inference and  evaluation\n",
    "print(\"\\n=== CLEANING MEMORY FOR INFERENCE ===\")\n",
    "del model, base_model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"Reloading Base Model + Best Adapter for Inference...\")\n",
    "\n",
    "inference_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "inference_base.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "inference_model = PeftModel.from_pretrained(inference_base, adapter_path)\n",
    "inference_model.eval()\n",
    "\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=os.path.join(OUTPUT_DIR, \"eval_temp\"),\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "predictor = Trainer(\n",
    "    model=inference_model,\n",
    "    args=eval_args,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"Predicting on Test (Gold Dev) Set...\")\n",
    "pred_output = predictor.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred_output.predictions), 1.0, 5.0)\n",
    "\n",
    "# metrics calculations\n",
    "# Retrieve True Labels and Metadata from the dataframe\n",
    "# (Order is preserved by the Trainer)\n",
    "y_true = dev_df[\"label\"].to_numpy(float)\n",
    "y_stdev = dev_df[\"stdev\"].to_numpy(float)\n",
    "groups = dev_df[\"group_id\"].tolist()\n",
    "\n",
    "# Global Spearman & MAE\n",
    "global_spearman = spearmanr(y_true, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(y_true - raw_preds))\n",
    "\n",
    "# Accuracy within Std Dev\n",
    "errors = np.abs(raw_preds - y_true)\n",
    "within_stdev = errors <= y_stdev\n",
    "acc_stdev = float(np.mean(within_stdev))\n",
    "\n",
    "# Macro-Spearman\n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_corrs = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = y_true[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "    # variance to calculate correlation\n",
    "    if len(set(g_true)) > 1:\n",
    "        corr = spearmanr(g_true, g_pred).correlation\n",
    "        if not np.isnan(corr):\n",
    "            group_corrs.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_corrs)) if group_corrs else 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL RESULTS (Gold + Synth SFT)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within Stdev: {acc_stdev:.4f}\")\n",
    "print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0G-FztG85mB",
    "outputId": "50d747d5-3cc6-491b-b1e2-779cb6d62dc4"
   },
   "outputs": [],
   "source": [
    "# bootstrapping\n",
    "def bootstrap_full_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    res_global_sps = []\n",
    "    res_macro_sps = []\n",
    "    res_maes = []\n",
    "    res_accs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # Global Spearman\n",
    "        gs = spearmanr(bt_true, bt_pred).correlation\n",
    "        res_global_sps.append(gs if not np.isnan(gs) else 0.0)\n",
    "\n",
    "        # MAE\n",
    "        res_maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # Accuracy within Stdev\n",
    "        res_accs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # Macro Spearman\n",
    "        # Re-group based on resampled data\n",
    "        local_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_map[g].append(i)\n",
    "\n",
    "        local_corrs = []\n",
    "        for g, g_idxs in local_map.items():\n",
    "            gt = bt_true[g_idxs]\n",
    "            gp = bt_pred[g_idxs]\n",
    "            if len(set(gt)) > 1:\n",
    "                c = spearmanr(gt, gp).correlation\n",
    "                if not np.isnan(c):\n",
    "                    local_corrs.append(c)\n",
    "\n",
    "        if local_corrs:\n",
    "            res_macro_sps.append(np.mean(local_corrs))\n",
    "        else:\n",
    "            res_macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"Global Spearman\": summarize(res_global_sps),\n",
    "        \"Macro Spearman\": summarize(res_macro_sps),\n",
    "        \"MAE\": summarize(res_maes),\n",
    "        \"Acc w/in Stdev\": summarize(res_accs),\n",
    "    }\n",
    "\n",
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "bootstrap_stats = bootstrap_full_metrics(\n",
    "    y_true=y_true,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=y_stdev,\n",
    "    groups=groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_stats.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
