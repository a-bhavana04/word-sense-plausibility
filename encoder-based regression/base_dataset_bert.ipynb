{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nZ8FTF2ijVR",
    "outputId": "dc4112bd-23bb-4a93-a3cd-d4e61922d639"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE9P_zjlipNk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVexX7mAirVQ"
   },
   "outputs": [],
   "source": [
    "#seeding for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEGC_AtAitan"
   },
   "outputs": [],
   "source": [
    "TRAIN_JSON_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "DEV_JSON_PATH   = \"/content/drive/MyDrive/nlp/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75KVWVn8iv0f"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOZDnaI-ix0G"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IqnlFYEizmu"
   },
   "outputs": [],
   "source": [
    "#building input examples\n",
    "def build_examples(records):\n",
    "    # flattening nested lists so every item is a dict\n",
    "    def flatten(xs):\n",
    "        for x in xs:\n",
    "            if isinstance(x, list):\n",
    "                yield from flatten(x)\n",
    "            else:\n",
    "                yield x\n",
    "\n",
    "    # If a single dict is passed\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "\n",
    "    # Flatten any nested structure\n",
    "    records = list(flatten(records))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "      \n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        end = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        meaning_txt = (\n",
    "            \"Meaning (intended definition):\\n\"\n",
    "            f\"{meaning}\"\n",
    "        )\n",
    "\n",
    "        story_parts = [pre, sent]\n",
    "        if end:\n",
    "            story_parts.append(end)\n",
    "\n",
    "        story_txt = \"Story:\\n\" + \"\\n\".join(story_parts)\n",
    "\n",
    "        ex_sent = (r.get(\"example_sentence\") or \"\").strip()\n",
    "        if ex_sent:\n",
    "            story_txt += f\"\\nExample sentence: {ex_sent}\"\n",
    "\n",
    "        label = float(r.get(\"average\", 0.0))\n",
    "\n",
    "        gid = f\"{r.get('homonym', '')}||{sent}\"\n",
    "\n",
    "        out.append({\n",
    "            \"context\": story_txt,\n",
    "            \"meaning\": meaning_txt,\n",
    "            \"label\": label,\n",
    "            \"stdev\": float(r.get(\"stdev\", 0)),\n",
    "            \"group_id\": gid,\n",
    "            \"choices\": r.get(\"choices\"),\n",
    "            \"nonsensical\": r.get(\"nonsensical\"),\n",
    "            \"sample_id\": r.get(\"sample_id\")\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUOeVXjIi2J8"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_examples = build_examples(train_records)\n",
    "dev_examples   = build_examples(dev_records)\n",
    "\n",
    "train_df = pd.DataFrame(train_examples)\n",
    "dev_df   = pd.DataFrame(dev_examples)\n",
    "\n",
    "dev_labels = dev_df[\"label\"].to_numpy(float)\n",
    "dev_stdevs = dev_df[\"stdev\"].to_numpy(float)\n",
    "dev_groups = dev_df[\"group_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiGBK2vRi_MV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting original train_df into 80/20\n",
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# building HF DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df_split, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df_split, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "babe1b1790d442eba7f7b6919e2cac0c",
      "36cb65d13b73415da088f316e422ff9b",
      "455f5915ad26448d89acef630a6b892d",
      "5f458e0c496a4ed6ab80c03b8bd4d849",
      "d92bae80482245e2bd171fffbc72c51c",
      "4be1a092e2dd462fa61129fa41983a26",
      "965e519de5204af489f04c3b3cd8e482",
      "e57ba46e770b449c8cbee5f8c79eed73",
      "883bf72f073642ba84f900a4817e103b",
      "63adbfe5e2c54bcfa4fbf04db378560c",
      "897a1be7504544f38804b02c81ee6736",
      "a69ed743a9524c8eaa0dee11663a8180",
      "fbe5b4f2ded04681ad653cc2bd261d01",
      "727f0a22730343e4b12f70f5799410fd",
      "c316a2f551384cd0beccb5e94454921d",
      "b886024a237a4abc88b841d57bf59de1",
      "f95da7d0b1114f13bd3bb2b1081fc2a2",
      "38b11ad6443f4a45b90d5dd75bc2c952",
      "ba2c3ea3e684494f9ee5198ab64a7975",
      "fd0145722b084dd5a2a05921760befc4",
      "56ce7574fb904cec86b8c26acc5f145e",
      "2eb20700c65941e18ecd4a48624ed3c0",
      "6ac3352a2cc2496fb065c695dc4a67c3",
      "2c358e4d412f4ab5b9aad062626011f8",
      "a414ab792b0f4835a10ac3b6f9146285",
      "72b48b0c9fba449ca1a7b98eec70e7af",
      "5253fd1edf7240689d46e5bfa069fc90",
      "5cd2c75730a64cc8b0a6c50b1838d206",
      "9faa871010174db89ea7145a620f70af",
      "9c0ce78c4f0a4eb9a644f6fcac73bd53",
      "2bc1c82874c54d5f8c2780b2701393f3",
      "7fc86cb5445848cb97f358149156e367",
      "60e39e66bdc740399866fc58b6c9b7ad",
      "ff4a134efcbd4cae8241707a8c06785e",
      "78a72b5d6dbe40cd9ddcc73b6fe91459",
      "668b34fc994143b29968697806178518",
      "3412fdbd03af4195a93a180bd97071ca",
      "b4527185127b4da9b36e83892952dc3c",
      "26ce773254ad4a62931f32db471294ad",
      "5b800b23c75a49c586bd80a828b81473",
      "79a0b41196a94a129be51de95d9f702e",
      "019d0cdda3a84ba7905f7b9ef477e16e",
      "7873c3a3777a48929fc0562ca13e70ba",
      "fd06bc4294444f55b456f4d648adb99d",
      "b762024adf1944dbb6f2f9317b48329b",
      "7b7a43d6f21443e4aef1dda76cda01d6",
      "6fda9bf5369a4df6b05607c980fdd598",
      "5f8939cd3e6d462ba722c22b030819cd",
      "6e9caacf99814ed18780287b4831e3fe",
      "2476db1af1a34723b015587eeba9050c",
      "bbc2c5dd3bb74ef4915eb419cf7d83f6",
      "5a76f9d36c0b4c518fa628417adca76c",
      "6f7c80902ae145ff9dbd144bcdd7ceb9",
      "75ff8dbb65394962992b81df56ae9c39",
      "5d22afef48df466ea6282f4d33f87693",
      "303bb39a57e843b3ba678a448595f315",
      "3a37854748bd444492657563199674a8",
      "51705720af0a464bba1b5c25a207e863",
      "2d1cf15ed0294ee8b3791b0e8782faac",
      "1224504a643c40819413693c5cadc32f",
      "85629115d1c24e5ab6b802a2ca24d4ec",
      "1b99ed2c258c4ee7beac0faea3d47f3d",
      "263c03371470491ebff6d11d1340853b",
      "25d58dce40014c38a4e9e0272019afce",
      "ca08a973da5247d1a45afa5480ff6644",
      "517eeb90bd6e42adaaffa2fc0ab75507",
      "f305864419f14474abf4dd58f572bd33",
      "40c459bba187492da92672d9b2a7311b",
      "04f3c8978db54b5fb115969f5eef0dba",
      "0506d4a1f93a4852aca04fa5652621f1",
      "1e3c015fa1954d118ee6ba6b86257b0f",
      "5d40ce9a9f184c6aaf2fe06129bd9c8a",
      "700894e8181540f19acec0c9a30be419",
      "985d0be1af8c45d1b5c8c4eb696ca4e9",
      "0863c3babe594049aebf1f190d8c1ea6",
      "10c92dbedf8f43d08e960144e5e4dcce",
      "b73d6ab6fb8f467583f07f1aafa65b2f"
     ]
    },
    "id": "8GRXwVcxjC5U",
    "outputId": "9b156f75-b41b-41e7-f63b-c210bce2c6d2"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "MODEL_NAME = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"context\"],\n",
    "        batch[\"meaning\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove non-tensor columns\n",
    "for col in [\"context\", \"meaning\", \"stdev\", \"group_id\", \"sample_id\"]:\n",
    "    if col in tokenized[\"train\"].column_names:\n",
    "        tokenized = tokenized.remove_columns(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "3a4c6f57343f4968b84ccf3f74ebc78a",
      "ac622c737489429580ecd545ae2a7333",
      "ceb5edb217064886acddf595746212a8",
      "206927ba103e409187d92c1ec40a34c7",
      "8c304f9ce67a41e289301cefade7f7df",
      "80ac6a9b31064be7ab3e40109fbcb655",
      "6c8103a4c9014c3b816e22305ce6449b",
      "ac83633dc0e74689ac2821ee3c366fdf",
      "0b64f87db68f472bae13a2b3531efeb3",
      "d645127027874fd0ba869429f47423aa",
      "7657140a7e15435e9401732028ae9776"
     ]
    },
    "id": "ejXGzR6ukYbi",
    "outputId": "e1f3d1d6-d486-4638-d381-8413d574ac9e"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnvkJpNkko0v",
    "outputId": "1178056b-367f-4843-96a7-ced3b9b8b974"
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "ef compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr),\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= None,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],   \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "pesEh2dLkrbr",
    "outputId": "3bbe8e8a-8860-437c-bc6a-7be41c63c2f9"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "n0pke0BBk3Rc",
    "outputId": "fb87fb7e-7db4-4c14-990a-2a77d965385c"
   },
   "outputs": [],
   "source": [
    "print(\"\\nFINAL EVAL ON DEV (TEST)\")\n",
    "\n",
    "pred = trainer.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred.predictions), 1.0, 5.0)\n",
    "\n",
    "# Global Spearman & MAE \n",
    "global_spearman = spearmanr(dev_labels, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(dev_labels - raw_preds))\n",
    "\n",
    "# Macro-Spearman \n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(dev_groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_sps = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = dev_labels[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "\n",
    "    if np.all(g_true == g_true[0]):\n",
    "        continue\n",
    "\n",
    "    corr = spearmanr(g_true, g_pred).correlation\n",
    "    if not np.isnan(corr):\n",
    "        group_sps.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_sps)) if group_sps else 0.0\n",
    "\n",
    "# Accuracy within stdev \n",
    "errors = np.abs(raw_preds - dev_labels)\n",
    "within = errors <= dev_stdevs\n",
    "acc_stdev = float(np.mean(within))\n",
    "\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within stdev: {acc_stdev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMSTmllck9lq"
   },
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def bootstrap_test_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    global_sps = []\n",
    "    macro_sps = []\n",
    "    maes = []\n",
    "    acc_stdevs = []\n",
    "\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, gid in enumerate(groups):\n",
    "        group_to_indices[gid].append(i)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # ---- Global Spearman ----\n",
    "        rho = spearmanr(bt_true, bt_pred).correlation\n",
    "        global_sps.append(rho)\n",
    "\n",
    "        # ---- MAE ----\n",
    "        maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # ---- Accuracy within stdev ----\n",
    "        acc_stdevs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # ---- Macro Spearman ----\n",
    "        local_group_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_group_map[g].append(i)\n",
    "\n",
    "        group_corrs = []\n",
    "        for g, idxs in local_group_map.items():\n",
    "            gt = bt_true[idxs]\n",
    "            gp = bt_pred[idxs]\n",
    "\n",
    "            if np.all(gt == gt[0]):\n",
    "                continue\n",
    "\n",
    "            c = spearmanr(gt, gp).correlation\n",
    "            if not np.isnan(c):\n",
    "                group_corrs.append(c)\n",
    "\n",
    "        if group_corrs:\n",
    "            macro_sps.append(np.mean(group_corrs))\n",
    "        else:\n",
    "            macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"global_spearman\": summarize(global_sps),\n",
    "        \"macro_spearman\": summarize(macro_sps),\n",
    "        \"mae\": summarize(maes),\n",
    "        \"acc_within_stdev\": summarize(acc_stdevs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq6j7Qk0k-PE",
    "outputId": "79b27d5a-9ad2-4e21-ea88-639d990614dc"
   },
   "outputs": [],
   "source": [
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "\n",
    "bootstrap_results = bootstrap_test_metrics(\n",
    "    y_true=dev_labels,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=dev_stdevs,\n",
    "    groups=dev_groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_results.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
