{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_handwritten-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_builtin-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nbstripout\n",
      "  Downloading nbstripout-0.8.2-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting nbformat (from nbstripout)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->nbstripout)\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat->nbstripout)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.9.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.14.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat->nbstripout)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat->nbstripout)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat->nbstripout)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat->nbstripout)\n",
      "  Downloading rpds_py-0.30.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
      "Downloading nbstripout-0.8.2-py2.py3-none-any.whl (17 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m38.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m50.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m77.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.30.0-cp311-cp311-macosx_11_0_arm64.whl (359 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m359.7/359.7 kB\u001b[0m \u001b[31m4.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:04\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: fastjsonschema, rpds-py, attrs, referencing, jsonschema-specifications, jsonschema, nbformat, nbstripout\n",
      "Successfully installed attrs-25.4.0 fastjsonschema-2.21.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 nbformat-5.10.4 nbstripout-0.8.2 referencing-0.37.0 rpds-py-0.30.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nbstripout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout base_dataset_bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert base_dataset_bert.ipynb \\\n",
    "  --to notebook \\\n",
    "  --execute \\\n",
    "  --inplace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nZ8FTF2ijVR",
    "outputId": "dc4112bd-23bb-4a93-a3cd-d4e61922d639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XE9P_zjlipNk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVexX7mAirVQ"
   },
   "outputs": [],
   "source": [
    "#seeding for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AEGC_AtAitan"
   },
   "outputs": [],
   "source": [
    "TRAIN_JSON_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "DEV_JSON_PATH   = \"/content/drive/MyDrive/nlp/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "75KVWVn8iv0f"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FOZDnaI-ix0G"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IqnlFYEizmu"
   },
   "outputs": [],
   "source": [
    "#building input examples\n",
    "def build_examples(records):\n",
    "    # flattening nested lists so every item is a dict\n",
    "    def flatten(xs):\n",
    "        for x in xs:\n",
    "            if isinstance(x, list):\n",
    "                yield from flatten(x)\n",
    "            else:\n",
    "                yield x\n",
    "\n",
    "    # If a single dict is passed\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "\n",
    "    # Flatten any nested structure\n",
    "    records = list(flatten(records))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "      \n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        end = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        meaning_txt = (\n",
    "            \"Meaning (intended definition):\\n\"\n",
    "            f\"{meaning}\"\n",
    "        )\n",
    "\n",
    "        story_parts = [pre, sent]\n",
    "        if end:\n",
    "            story_parts.append(end)\n",
    "\n",
    "        story_txt = \"Story:\\n\" + \"\\n\".join(story_parts)\n",
    "\n",
    "        ex_sent = (r.get(\"example_sentence\") or \"\").strip()\n",
    "        if ex_sent:\n",
    "            story_txt += f\"\\nExample sentence: {ex_sent}\"\n",
    "\n",
    "        label = float(r.get(\"average\", 0.0))\n",
    "\n",
    "        gid = f\"{r.get('homonym', '')}||{sent}\"\n",
    "\n",
    "        out.append({\n",
    "            \"context\": story_txt,\n",
    "            \"meaning\": meaning_txt,\n",
    "            \"label\": label,\n",
    "            \"stdev\": float(r.get(\"stdev\", 0)),\n",
    "            \"group_id\": gid,\n",
    "            \"choices\": r.get(\"choices\"),\n",
    "            \"nonsensical\": r.get(\"nonsensical\"),\n",
    "            \"sample_id\": r.get(\"sample_id\")\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUOeVXjIi2J8"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_examples = build_examples(train_records)\n",
    "dev_examples   = build_examples(dev_records)\n",
    "\n",
    "train_df = pd.DataFrame(train_examples)\n",
    "dev_df   = pd.DataFrame(dev_examples)\n",
    "\n",
    "dev_labels = dev_df[\"label\"].to_numpy(float)\n",
    "dev_stdevs = dev_df[\"stdev\"].to_numpy(float)\n",
    "dev_groups = dev_df[\"group_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiGBK2vRi_MV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting original train_df into 80/20\n",
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# building HF DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df_split, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df_split, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "babe1b1790d442eba7f7b6919e2cac0c",
      "36cb65d13b73415da088f316e422ff9b",
      "455f5915ad26448d89acef630a6b892d",
      "5f458e0c496a4ed6ab80c03b8bd4d849",
      "d92bae80482245e2bd171fffbc72c51c",
      "4be1a092e2dd462fa61129fa41983a26",
      "965e519de5204af489f04c3b3cd8e482",
      "e57ba46e770b449c8cbee5f8c79eed73",
      "883bf72f073642ba84f900a4817e103b",
      "63adbfe5e2c54bcfa4fbf04db378560c",
      "897a1be7504544f38804b02c81ee6736",
      "a69ed743a9524c8eaa0dee11663a8180",
      "fbe5b4f2ded04681ad653cc2bd261d01",
      "727f0a22730343e4b12f70f5799410fd",
      "c316a2f551384cd0beccb5e94454921d",
      "b886024a237a4abc88b841d57bf59de1",
      "f95da7d0b1114f13bd3bb2b1081fc2a2",
      "38b11ad6443f4a45b90d5dd75bc2c952",
      "ba2c3ea3e684494f9ee5198ab64a7975",
      "fd0145722b084dd5a2a05921760befc4",
      "56ce7574fb904cec86b8c26acc5f145e",
      "2eb20700c65941e18ecd4a48624ed3c0",
      "6ac3352a2cc2496fb065c695dc4a67c3",
      "2c358e4d412f4ab5b9aad062626011f8",
      "a414ab792b0f4835a10ac3b6f9146285",
      "72b48b0c9fba449ca1a7b98eec70e7af",
      "5253fd1edf7240689d46e5bfa069fc90",
      "5cd2c75730a64cc8b0a6c50b1838d206",
      "9faa871010174db89ea7145a620f70af",
      "9c0ce78c4f0a4eb9a644f6fcac73bd53",
      "2bc1c82874c54d5f8c2780b2701393f3",
      "7fc86cb5445848cb97f358149156e367",
      "60e39e66bdc740399866fc58b6c9b7ad",
      "ff4a134efcbd4cae8241707a8c06785e",
      "78a72b5d6dbe40cd9ddcc73b6fe91459",
      "668b34fc994143b29968697806178518",
      "3412fdbd03af4195a93a180bd97071ca",
      "b4527185127b4da9b36e83892952dc3c",
      "26ce773254ad4a62931f32db471294ad",
      "5b800b23c75a49c586bd80a828b81473",
      "79a0b41196a94a129be51de95d9f702e",
      "019d0cdda3a84ba7905f7b9ef477e16e",
      "7873c3a3777a48929fc0562ca13e70ba",
      "fd06bc4294444f55b456f4d648adb99d",
      "b762024adf1944dbb6f2f9317b48329b",
      "7b7a43d6f21443e4aef1dda76cda01d6",
      "6fda9bf5369a4df6b05607c980fdd598",
      "5f8939cd3e6d462ba722c22b030819cd",
      "6e9caacf99814ed18780287b4831e3fe",
      "2476db1af1a34723b015587eeba9050c",
      "bbc2c5dd3bb74ef4915eb419cf7d83f6",
      "5a76f9d36c0b4c518fa628417adca76c",
      "6f7c80902ae145ff9dbd144bcdd7ceb9",
      "75ff8dbb65394962992b81df56ae9c39",
      "5d22afef48df466ea6282f4d33f87693",
      "303bb39a57e843b3ba678a448595f315",
      "3a37854748bd444492657563199674a8",
      "51705720af0a464bba1b5c25a207e863",
      "2d1cf15ed0294ee8b3791b0e8782faac",
      "1224504a643c40819413693c5cadc32f",
      "85629115d1c24e5ab6b802a2ca24d4ec",
      "1b99ed2c258c4ee7beac0faea3d47f3d",
      "263c03371470491ebff6d11d1340853b",
      "25d58dce40014c38a4e9e0272019afce",
      "ca08a973da5247d1a45afa5480ff6644",
      "517eeb90bd6e42adaaffa2fc0ab75507",
      "f305864419f14474abf4dd58f572bd33",
      "40c459bba187492da92672d9b2a7311b",
      "04f3c8978db54b5fb115969f5eef0dba",
      "0506d4a1f93a4852aca04fa5652621f1",
      "1e3c015fa1954d118ee6ba6b86257b0f",
      "5d40ce9a9f184c6aaf2fe06129bd9c8a",
      "700894e8181540f19acec0c9a30be419",
      "985d0be1af8c45d1b5c8c4eb696ca4e9",
      "0863c3babe594049aebf1f190d8c1ea6",
      "10c92dbedf8f43d08e960144e5e4dcce",
      "b73d6ab6fb8f467583f07f1aafa65b2f"
     ]
    },
    "id": "8GRXwVcxjC5U",
    "outputId": "9b156f75-b41b-41e7-f63b-c210bce2c6d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babe1b1790d442eba7f7b6919e2cac0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69ed743a9524c8eaa0dee11663a8180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac3352a2cc2496fb065c695dc4a67c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4a134efcbd4cae8241707a8c06785e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b762024adf1944dbb6f2f9317b48329b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303bb39a57e843b3ba678a448595f315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f305864419f14474abf4dd58f572bd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model\n",
    "MODEL_NAME = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"context\"],\n",
    "        batch[\"meaning\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove non-tensor columns\n",
    "for col in [\"context\", \"meaning\", \"stdev\", \"group_id\", \"sample_id\"]:\n",
    "    if col in tokenized[\"train\"].column_names:\n",
    "        tokenized = tokenized.remove_columns(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "3a4c6f57343f4968b84ccf3f74ebc78a",
      "ac622c737489429580ecd545ae2a7333",
      "ceb5edb217064886acddf595746212a8",
      "206927ba103e409187d92c1ec40a34c7",
      "8c304f9ce67a41e289301cefade7f7df",
      "80ac6a9b31064be7ab3e40109fbcb655",
      "6c8103a4c9014c3b816e22305ce6449b",
      "ac83633dc0e74689ac2821ee3c366fdf",
      "0b64f87db68f472bae13a2b3531efeb3",
      "d645127027874fd0ba869429f47423aa",
      "7657140a7e15435e9401732028ae9776"
     ]
    },
    "id": "ejXGzR6ukYbi",
    "outputId": "e1f3d1d6-d486-4638-d381-8413d574ac9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4c6f57343f4968b84ccf3f74ebc78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnvkJpNkko0v",
    "outputId": "1178056b-367f-4843-96a7-ced3b9b8b974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3159646010.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "ef compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr),\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= None,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],   \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "pesEh2dLkrbr",
    "outputId": "3bbe8e8a-8860-437c-bc6a-7be41c63c2f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8e79d44cc76670a825631f79b078fafbaac40ed9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanand\u001b[0m (\u001b[33mbanand-university-of-massachusetts-amherst\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251216_003648-urrgeboi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/urrgeboi' target=\"_blank\">dulcet-resonance-15</a></strong> to <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface' target=\"_blank\">https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/urrgeboi' target=\"_blank\">https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/urrgeboi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.045900</td>\n",
       "      <td>1.440315</td>\n",
       "      <td>-0.037824</td>\n",
       "      <td>1.036685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.466700</td>\n",
       "      <td>1.404677</td>\n",
       "      <td>0.081659</td>\n",
       "      <td>1.020785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.420600</td>\n",
       "      <td>1.385916</td>\n",
       "      <td>0.182091</td>\n",
       "      <td>1.009345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.282200</td>\n",
       "      <td>1.391662</td>\n",
       "      <td>0.210767</td>\n",
       "      <td>1.008388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.065700</td>\n",
       "      <td>1.476352</td>\n",
       "      <td>0.219031</td>\n",
       "      <td>1.003682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>1.562663</td>\n",
       "      <td>0.225634</td>\n",
       "      <td>1.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.735900</td>\n",
       "      <td>1.596169</td>\n",
       "      <td>0.228352</td>\n",
       "      <td>1.025940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.711900</td>\n",
       "      <td>1.623114</td>\n",
       "      <td>0.233995</td>\n",
       "      <td>1.027559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.683200</td>\n",
       "      <td>1.617211</td>\n",
       "      <td>0.240123</td>\n",
       "      <td>1.024856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.637300</td>\n",
       "      <td>1.625178</td>\n",
       "      <td>0.241142</td>\n",
       "      <td>1.028204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=570, training_loss=1.4582770314132958, metrics={'train_runtime': 97.1056, 'train_samples_per_second': 187.837, 'train_steps_per_second': 5.87, 'total_flos': 2399551280087040.0, 'train_loss': 1.4582770314132958, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "n0pke0BBk3Rc",
    "outputId": "fb87fb7e-7db4-4c14-990a-2a77d965385c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL EVAL ON DEV (TEST)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Spearman:       0.2411\n",
      "Macro Spearman:        0.2056\n",
      "MAE:                   1.0282\n",
      "Accuracy within stdev: 0.5085\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFINAL EVAL ON DEV (TEST)\")\n",
    "\n",
    "pred = trainer.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred.predictions), 1.0, 5.0)\n",
    "\n",
    "# Global Spearman & MAE \n",
    "global_spearman = spearmanr(dev_labels, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(dev_labels - raw_preds))\n",
    "\n",
    "# Macro-Spearman \n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(dev_groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_sps = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = dev_labels[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "\n",
    "    if np.all(g_true == g_true[0]):\n",
    "        continue\n",
    "\n",
    "    corr = spearmanr(g_true, g_pred).correlation\n",
    "    if not np.isnan(corr):\n",
    "        group_sps.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_sps)) if group_sps else 0.0\n",
    "\n",
    "# Accuracy within stdev \n",
    "errors = np.abs(raw_preds - dev_labels)\n",
    "within = errors <= dev_stdevs\n",
    "acc_stdev = float(np.mean(within))\n",
    "\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within stdev: {acc_stdev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMSTmllck9lq"
   },
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def bootstrap_test_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    global_sps = []\n",
    "    macro_sps = []\n",
    "    maes = []\n",
    "    acc_stdevs = []\n",
    "\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, gid in enumerate(groups):\n",
    "        group_to_indices[gid].append(i)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # ---- Global Spearman ----\n",
    "        rho = spearmanr(bt_true, bt_pred).correlation\n",
    "        global_sps.append(rho)\n",
    "\n",
    "        # ---- MAE ----\n",
    "        maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # ---- Accuracy within stdev ----\n",
    "        acc_stdevs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # ---- Macro Spearman ----\n",
    "        local_group_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_group_map[g].append(i)\n",
    "\n",
    "        group_corrs = []\n",
    "        for g, idxs in local_group_map.items():\n",
    "            gt = bt_true[idxs]\n",
    "            gp = bt_pred[idxs]\n",
    "\n",
    "            if np.all(gt == gt[0]):\n",
    "                continue\n",
    "\n",
    "            c = spearmanr(gt, gp).correlation\n",
    "            if not np.isnan(c):\n",
    "                group_corrs.append(c)\n",
    "\n",
    "        if group_corrs:\n",
    "            macro_sps.append(np.mean(group_corrs))\n",
    "        else:\n",
    "            macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"global_spearman\": summarize(global_sps),\n",
    "        \"macro_spearman\": summarize(macro_sps),\n",
    "        \"mae\": summarize(maes),\n",
    "        \"acc_within_stdev\": summarize(acc_stdevs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq6j7Qk0k-PE",
    "outputId": "79b27d5a-9ad2-4e21-ea88-639d990614dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOOTSTRAP RESULTS (TEST SET)\n",
      "global_spearman     : 0.2422 [0.1702, 0.3137]\n",
      "macro_spearman      : 0.1923 [0.0973, 0.2844]\n",
      "mae                 : 1.0276 [0.9724, 1.0909]\n",
      "acc_within_stdev    : 0.5084 [0.4677, 0.5476]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "\n",
    "bootstrap_results = bootstrap_test_metrics(\n",
    "    y_true=dev_labels,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=dev_stdevs,\n",
    "    groups=dev_groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_results.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}