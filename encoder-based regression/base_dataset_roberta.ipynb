{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nZ8FTF2ijVR",
    "outputId": "a7c906ad-c689-4ce6-9f03-266031a1d7dd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE9P_zjlipNk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVexX7mAirVQ"
   },
   "outputs": [],
   "source": [
    "#seeding for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEGC_AtAitan"
   },
   "outputs": [],
   "source": [
    "TRAIN_JSON_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "DEV_JSON_PATH   = \"/content/drive/MyDrive/nlp/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75KVWVn8iv0f"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOZDnaI-ix0G"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IqnlFYEizmu"
   },
   "outputs": [],
   "source": [
    "#building input examples\n",
    "def build_examples(records):\n",
    "    # flattening nested lists so every item is a dict\n",
    "    def flatten(xs):\n",
    "        for x in xs:\n",
    "            if isinstance(x, list):\n",
    "                yield from flatten(x)\n",
    "            else:\n",
    "                yield x\n",
    "\n",
    "\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "\n",
    "    records = list(flatten(records))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        end = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        meaning_txt = (\n",
    "            \"Meaning (intended definition):\\n\"\n",
    "            f\"{meaning}\"\n",
    "        )\n",
    "\n",
    "        story_parts = [pre, sent]\n",
    "        if end:\n",
    "            story_parts.append(end)\n",
    "\n",
    "        story_txt = \"Story:\\n\" + \"\\n\".join(story_parts)\n",
    "\n",
    "        ex_sent = (r.get(\"example_sentence\") or \"\").strip()\n",
    "        if ex_sent:\n",
    "            story_txt += f\"\\nExample sentence: {ex_sent}\"\n",
    "\n",
    "        label = float(r.get(\"average\", 0.0))\n",
    "\n",
    "        gid = f\"{r.get('homonym', '')}||{sent}\"\n",
    "\n",
    "        out.append({\n",
    "            \"context\": story_txt,\n",
    "            \"meaning\": meaning_txt,\n",
    "            \"label\": label,\n",
    "            \"stdev\": float(r.get(\"stdev\", 0)),\n",
    "            \"group_id\": gid,\n",
    "            \"choices\": r.get(\"choices\"),\n",
    "            \"nonsensical\": r.get(\"nonsensical\"),\n",
    "            \"sample_id\": r.get(\"sample_id\")\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUOeVXjIi2J8"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_examples = build_examples(train_records)\n",
    "dev_examples   = build_examples(dev_records)\n",
    "\n",
    "train_df = pd.DataFrame(train_examples)\n",
    "dev_df   = pd.DataFrame(dev_examples)\n",
    "\n",
    "dev_labels = dev_df[\"label\"].to_numpy(float)\n",
    "dev_stdevs = dev_df[\"stdev\"].to_numpy(float)\n",
    "dev_groups = dev_df[\"group_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiGBK2vRi_MV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting original train_df into 80/20\n",
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# building HF DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df_split, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df_split, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "684c3f74ad624ec7b5a72ae795d1e223",
      "4d346c76cc054f2ca8e506cf38bf790f",
      "ac3f220e473b418c82b2ef4236b708b7",
      "0ca8e15a39b14366a18fc173d8ef0ce1",
      "820d9f22e43a4a17bb3fe0fecab45665",
      "0c4a8db89e6e44eebab069f5ac67cbae",
      "b7ffb3cb447a4beb8cbfe30d76eb7717",
      "97f62e0727f641c0b857f14538b250e4",
      "11d91efc950a489bbf90c7877fbd423d",
      "7c99ca19728546629d19783cec2d7e43",
      "22aaaeb628dc47e3b66a0d879b8fba8e",
      "7d16d5d8e748419daf7de9d8d4a7457d",
      "55201c59c91c4ac490de8539e1cc06f8",
      "5faed75317714191a904ae7342d7f7de",
      "ed8dfbf6c14a459e88c436aa237b695c",
      "6d85ee938cc5494d9ad97e883690dd2f",
      "34bb1a4f8b9b472f8c7c4b5a38358db8",
      "c2b85e1e8bfc45c0be14056bc9199eae",
      "1f73e69ea4a042f582646640e0760c79",
      "1697dec4d2314fce839d17b35e83b861",
      "cf576454873b49f786342cd0ae4af53f",
      "9a868a9d1a9f4172a551d3255889a4e8",
      "d721f1012a404214b255c77ee072b25d",
      "cf151b0d98694f37ad884bf9368e0136",
      "bcadc36ac33740c292da7c5cf2a3fa65",
      "4e995cad986b433db416ce11182f795b",
      "534aa03d46524952ae3b6568d4dfc1f6",
      "c237a30a4dea46b4a854f6a3f7369006",
      "3dfca0d0642b4ebda7be51246ee51331",
      "b30d50908e884001915af43628770723",
      "7cafcde2b75840c994485c8f922947e0",
      "3cbad4c9331d40bc9f42975016905e53",
      "a5125c37e2dd49c69f9be4f4f13d9a39",
      "4d9b4e5fab774281936d120fad81c050",
      "87aa369d205b49f7b06307531c79ecd9",
      "c842177519c5453083f9164de7f2105c",
      "d799e14013834b67ad69ba38fa16bcc1",
      "2de8636b163147ad9c2dd34a2787f6cf",
      "0c00c60b567d4b90aedeece1c7496ae1",
      "55929d3096414ef0bfcc22d13c1c5992",
      "f1d7e7744da44103a43519bdb78fe20e",
      "4753866e90d945a2900d21a8b70fc2db",
      "bb3a8bdfea4943899a1b7e81483aa553",
      "37d4541e0335411eae81cb8afb8816b5",
      "995c3592bbde47c3b46a38eed2408a34",
      "310a8bab11634eff8d93611ac258bac1",
      "f2dbabb36cdf4f3f9d814db97c25a7c2",
      "e072b55ba160425e842fe02c51002fea",
      "147c222f363740fb975bc0aafc6f7120",
      "8091882b7558496fb5d56530e3b19872",
      "8d45de0a74004ffda1e4dcabb13ca594",
      "778bc2ee943c43f79f1f9a6c4e87ee21",
      "07bf08b88b1749859d9ec5bb8b662fe8",
      "1e683f438d2b47f49913335f55585863",
      "d5c8c0e02523412d9055dd829d61d06d",
      "caa6e0b7db07415a9069d62bd9ef5055",
      "37eaf85646d146b58c702364ab3a5001",
      "b38c800a8006439dbcf0ed450def0686",
      "a479ed3b3cb3491585ac1d648c7216d3",
      "842da3cfbb674272a20a43d0f803ea04",
      "cef4e9cbe7784a2d8e6f85eb827d814f",
      "984571ea1e694f2bbcfd9600eb780330",
      "c8a24b30d38340b39b997dfbb12650a1",
      "482e2ee30f7c486eb363a09798c6ccfb",
      "3d2665ef98f94b79a3891685550b8c90",
      "0ca1fc4a79fc45e386df08471e8b6d5a",
      "013475d55def4536ba7d46f97d501c42",
      "0c002c51a06841f5aa9bf5395a3e7622",
      "869ea61624184c8d81832a0aafcf1ef2",
      "4ec2857fde194a1dbcbe8998b4453282",
      "7952bb4da8a54a5b8c3eb8df44da47c0",
      "6b5878c056e542019548378321b26fdd",
      "e5e387b48ecb49949396695b6613bdc3",
      "9a6793f80fbc4c489fa7a3134ed64894",
      "a4bb651d1e9d4deca717550d809f9bd0",
      "0a36328e619a4972a43ece1db1d05710",
      "dcc2cd4088d4441bbe33e779cc8386d3",
      "57398ca0ec944f56b655cac3547e2323",
      "5d6e841f90724e1aac5aff9e4751e002",
      "1d20f951b38543a0863ab174622f4398",
      "54f6432e6aef4dd1bda556705e358d20",
      "534be7841e98495480daa5a010405339",
      "80856070c6db4df4aa73e1e537d695a4",
      "f9b094b8191447f1ac9ef115cea786be",
      "25d239870a624dce99891c100c72b384",
      "3ddbd397ad1d47a58931a5390e63e58d",
      "cb7eb358b6ed404aa2fb6f54f6410c93",
      "ef27010c1ca4489e82e9f42202cef9d9"
     ]
    },
    "id": "8GRXwVcxjC5U",
    "outputId": "3c11f703-cf37-4576-f901-db7284a14f76"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "MODEL_NAME = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"context\"],\n",
    "        batch[\"meaning\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove non-tensor columns\n",
    "for col in [\"context\", \"meaning\", \"stdev\", \"group_id\", \"sample_id\"]:\n",
    "    if col in tokenized[\"train\"].column_names:\n",
    "        tokenized = tokenized.remove_columns(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "38206fc8ff324b8fbe231366d2e139f0",
      "9b1bf089885a4e2e8331fe74cb2b1d80",
      "c883eb4025054dbe9b0da9f1038aecd6",
      "495cbb65f48942f6be1008d5b744f6d2",
      "76f234773f55450086310c4f1acefe4b",
      "ab926003be1d497f8032a69b43d83391",
      "bf0873379f45479682a6735994734b56",
      "3b5de50df58b4bd097b0dbb9d295eb6c",
      "c100ce4aca104bfcb0a1bca0a41f10ae",
      "136909a1fb81454087a05585c714d248",
      "097d732e4590410dbd2c28fba16b6249"
     ]
    },
    "id": "ejXGzR6ukYbi",
    "outputId": "1a94508b-0b78-445a-8f61-0ae05ee54472"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnvkJpNkko0v",
    "outputId": "92ee60b8-4fc9-48d5-a3f1-bbcc3de83fd9"
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr),\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= None,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"], \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "pesEh2dLkrbr",
    "outputId": "507e5a98-18cf-4350-a130-cb56dcbe6115"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "n0pke0BBk3Rc",
    "outputId": "abcbd19a-32b9-4e55-cc59-e3510986892e"
   },
   "outputs": [],
   "source": [
    "print(\"\\nFINAL EVAL ON DEV (TEST)\")\n",
    "\n",
    "pred = trainer.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred.predictions), 1.0, 5.0)\n",
    "\n",
    "# Global Spearman & MAE \n",
    "global_spearman = spearmanr(dev_labels, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(dev_labels - raw_preds))\n",
    "\n",
    "# Macro-Spearman \n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(dev_groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_sps = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = dev_labels[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "\n",
    "    if np.all(g_true == g_true[0]):\n",
    "        continue\n",
    "\n",
    "    corr = spearmanr(g_true, g_pred).correlation\n",
    "    if not np.isnan(corr):\n",
    "        group_sps.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_sps)) if group_sps else 0.0\n",
    "\n",
    "# Accuracy within stdev \n",
    "errors = np.abs(raw_preds - dev_labels)\n",
    "within = errors <= dev_stdevs\n",
    "acc_stdev = float(np.mean(within))\n",
    "\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within stdev: {acc_stdev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMSTmllck9lq"
   },
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def bootstrap_test_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    global_sps = []\n",
    "    macro_sps = []\n",
    "    maes = []\n",
    "    acc_stdevs = []\n",
    "\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, gid in enumerate(groups):\n",
    "        group_to_indices[gid].append(i)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # ---- Global Spearman ----\n",
    "        rho = spearmanr(bt_true, bt_pred).correlation\n",
    "        global_sps.append(rho)\n",
    "\n",
    "        # ---- MAE ----\n",
    "        maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # ---- Accuracy within stdev ----\n",
    "        acc_stdevs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # ---- Macro Spearman ----\n",
    "        local_group_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_group_map[g].append(i)\n",
    "\n",
    "        group_corrs = []\n",
    "        for g, idxs in local_group_map.items():\n",
    "            gt = bt_true[idxs]\n",
    "            gp = bt_pred[idxs]\n",
    "\n",
    "            if np.all(gt == gt[0]):\n",
    "                continue\n",
    "\n",
    "            c = spearmanr(gt, gp).correlation\n",
    "            if not np.isnan(c):\n",
    "                group_corrs.append(c)\n",
    "\n",
    "        if group_corrs:\n",
    "            macro_sps.append(np.mean(group_corrs))\n",
    "        else:\n",
    "            macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"global_spearman\": summarize(global_sps),\n",
    "        \"macro_spearman\": summarize(macro_sps),\n",
    "        \"mae\": summarize(maes),\n",
    "        \"acc_within_stdev\": summarize(acc_stdevs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq6j7Qk0k-PE",
    "outputId": "23f62e8d-2599-46f9-8728-d65c785c6ab0"
   },
   "outputs": [],
   "source": [
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "\n",
    "bootstrap_results = bootstrap_test_metrics(\n",
    "    y_true=dev_labels,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=dev_stdevs,\n",
    "    groups=dev_groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_results.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
