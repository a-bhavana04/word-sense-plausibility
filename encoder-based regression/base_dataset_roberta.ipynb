{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_handwritten-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/bhavanaanand/.local/lib/python3.11/site-packages/mylinear_cpp_builtin-0.0.0-py3.11-macosx-15.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nbstripout in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.8.2)\n",
      "Requirement already satisfied: nbformat in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbstripout) (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.9.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nbformat->nbstripout) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.30.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/bhavanaanand/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nbstripout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout base_dataset_roberta.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert base_dataset_roberta.ipynb \\\n",
    "  --to notebook \\\n",
    "  --execute \\\n",
    "  --inplace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to notebook base_dataset_roberta.ipynb --output base_dataset_roberta.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nZ8FTF2ijVR",
    "outputId": "a7c906ad-c689-4ce6-9f03-266031a1d7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XE9P_zjlipNk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVexX7mAirVQ"
   },
   "outputs": [],
   "source": [
    "#seeding for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AEGC_AtAitan"
   },
   "outputs": [],
   "source": [
    "TRAIN_JSON_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "DEV_JSON_PATH   = \"/content/drive/MyDrive/nlp/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "75KVWVn8iv0f"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FOZDnaI-ix0G"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IqnlFYEizmu"
   },
   "outputs": [],
   "source": [
    "#building input examples\n",
    "def build_examples(records):\n",
    "    # flattening nested lists so every item is a dict\n",
    "    def flatten(xs):\n",
    "        for x in xs:\n",
    "            if isinstance(x, list):\n",
    "                yield from flatten(x)\n",
    "            else:\n",
    "                yield x\n",
    "\n",
    "\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "\n",
    "    records = list(flatten(records))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        end = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        meaning_txt = (\n",
    "            \"Meaning (intended definition):\\n\"\n",
    "            f\"{meaning}\"\n",
    "        )\n",
    "\n",
    "        story_parts = [pre, sent]\n",
    "        if end:\n",
    "            story_parts.append(end)\n",
    "\n",
    "        story_txt = \"Story:\\n\" + \"\\n\".join(story_parts)\n",
    "\n",
    "        ex_sent = (r.get(\"example_sentence\") or \"\").strip()\n",
    "        if ex_sent:\n",
    "            story_txt += f\"\\nExample sentence: {ex_sent}\"\n",
    "\n",
    "        label = float(r.get(\"average\", 0.0))\n",
    "\n",
    "        gid = f\"{r.get('homonym', '')}||{sent}\"\n",
    "\n",
    "        out.append({\n",
    "            \"context\": story_txt,\n",
    "            \"meaning\": meaning_txt,\n",
    "            \"label\": label,\n",
    "            \"stdev\": float(r.get(\"stdev\", 0)),\n",
    "            \"group_id\": gid,\n",
    "            \"choices\": r.get(\"choices\"),\n",
    "            \"nonsensical\": r.get(\"nonsensical\"),\n",
    "            \"sample_id\": r.get(\"sample_id\")\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUOeVXjIi2J8"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_examples = build_examples(train_records)\n",
    "dev_examples   = build_examples(dev_records)\n",
    "\n",
    "train_df = pd.DataFrame(train_examples)\n",
    "dev_df   = pd.DataFrame(dev_examples)\n",
    "\n",
    "dev_labels = dev_df[\"label\"].to_numpy(float)\n",
    "dev_stdevs = dev_df[\"stdev\"].to_numpy(float)\n",
    "dev_groups = dev_df[\"group_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiGBK2vRi_MV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting original train_df into 80/20\n",
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# building HF DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df_split, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df_split, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "684c3f74ad624ec7b5a72ae795d1e223",
      "4d346c76cc054f2ca8e506cf38bf790f",
      "ac3f220e473b418c82b2ef4236b708b7",
      "0ca8e15a39b14366a18fc173d8ef0ce1",
      "820d9f22e43a4a17bb3fe0fecab45665",
      "0c4a8db89e6e44eebab069f5ac67cbae",
      "b7ffb3cb447a4beb8cbfe30d76eb7717",
      "97f62e0727f641c0b857f14538b250e4",
      "11d91efc950a489bbf90c7877fbd423d",
      "7c99ca19728546629d19783cec2d7e43",
      "22aaaeb628dc47e3b66a0d879b8fba8e",
      "7d16d5d8e748419daf7de9d8d4a7457d",
      "55201c59c91c4ac490de8539e1cc06f8",
      "5faed75317714191a904ae7342d7f7de",
      "ed8dfbf6c14a459e88c436aa237b695c",
      "6d85ee938cc5494d9ad97e883690dd2f",
      "34bb1a4f8b9b472f8c7c4b5a38358db8",
      "c2b85e1e8bfc45c0be14056bc9199eae",
      "1f73e69ea4a042f582646640e0760c79",
      "1697dec4d2314fce839d17b35e83b861",
      "cf576454873b49f786342cd0ae4af53f",
      "9a868a9d1a9f4172a551d3255889a4e8",
      "d721f1012a404214b255c77ee072b25d",
      "cf151b0d98694f37ad884bf9368e0136",
      "bcadc36ac33740c292da7c5cf2a3fa65",
      "4e995cad986b433db416ce11182f795b",
      "534aa03d46524952ae3b6568d4dfc1f6",
      "c237a30a4dea46b4a854f6a3f7369006",
      "3dfca0d0642b4ebda7be51246ee51331",
      "b30d50908e884001915af43628770723",
      "7cafcde2b75840c994485c8f922947e0",
      "3cbad4c9331d40bc9f42975016905e53",
      "a5125c37e2dd49c69f9be4f4f13d9a39",
      "4d9b4e5fab774281936d120fad81c050",
      "87aa369d205b49f7b06307531c79ecd9",
      "c842177519c5453083f9164de7f2105c",
      "d799e14013834b67ad69ba38fa16bcc1",
      "2de8636b163147ad9c2dd34a2787f6cf",
      "0c00c60b567d4b90aedeece1c7496ae1",
      "55929d3096414ef0bfcc22d13c1c5992",
      "f1d7e7744da44103a43519bdb78fe20e",
      "4753866e90d945a2900d21a8b70fc2db",
      "bb3a8bdfea4943899a1b7e81483aa553",
      "37d4541e0335411eae81cb8afb8816b5",
      "995c3592bbde47c3b46a38eed2408a34",
      "310a8bab11634eff8d93611ac258bac1",
      "f2dbabb36cdf4f3f9d814db97c25a7c2",
      "e072b55ba160425e842fe02c51002fea",
      "147c222f363740fb975bc0aafc6f7120",
      "8091882b7558496fb5d56530e3b19872",
      "8d45de0a74004ffda1e4dcabb13ca594",
      "778bc2ee943c43f79f1f9a6c4e87ee21",
      "07bf08b88b1749859d9ec5bb8b662fe8",
      "1e683f438d2b47f49913335f55585863",
      "d5c8c0e02523412d9055dd829d61d06d",
      "caa6e0b7db07415a9069d62bd9ef5055",
      "37eaf85646d146b58c702364ab3a5001",
      "b38c800a8006439dbcf0ed450def0686",
      "a479ed3b3cb3491585ac1d648c7216d3",
      "842da3cfbb674272a20a43d0f803ea04",
      "cef4e9cbe7784a2d8e6f85eb827d814f",
      "984571ea1e694f2bbcfd9600eb780330",
      "c8a24b30d38340b39b997dfbb12650a1",
      "482e2ee30f7c486eb363a09798c6ccfb",
      "3d2665ef98f94b79a3891685550b8c90",
      "0ca1fc4a79fc45e386df08471e8b6d5a",
      "013475d55def4536ba7d46f97d501c42",
      "0c002c51a06841f5aa9bf5395a3e7622",
      "869ea61624184c8d81832a0aafcf1ef2",
      "4ec2857fde194a1dbcbe8998b4453282",
      "7952bb4da8a54a5b8c3eb8df44da47c0",
      "6b5878c056e542019548378321b26fdd",
      "e5e387b48ecb49949396695b6613bdc3",
      "9a6793f80fbc4c489fa7a3134ed64894",
      "a4bb651d1e9d4deca717550d809f9bd0",
      "0a36328e619a4972a43ece1db1d05710",
      "dcc2cd4088d4441bbe33e779cc8386d3",
      "57398ca0ec944f56b655cac3547e2323",
      "5d6e841f90724e1aac5aff9e4751e002",
      "1d20f951b38543a0863ab174622f4398",
      "54f6432e6aef4dd1bda556705e358d20",
      "534be7841e98495480daa5a010405339",
      "80856070c6db4df4aa73e1e537d695a4",
      "f9b094b8191447f1ac9ef115cea786be",
      "25d239870a624dce99891c100c72b384",
      "3ddbd397ad1d47a58931a5390e63e58d",
      "cb7eb358b6ed404aa2fb6f54f6410c93",
      "ef27010c1ca4489e82e9f42202cef9d9"
     ]
    },
    "id": "8GRXwVcxjC5U",
    "outputId": "3c11f703-cf37-4576-f901-db7284a14f76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c3f74ad624ec7b5a72ae795d1e223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d16d5d8e748419daf7de9d8d4a7457d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d721f1012a404214b255c77ee072b25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9b4e5fab774281936d120fad81c050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995c3592bbde47c3b46a38eed2408a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa6e0b7db07415a9069d62bd9ef5055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013475d55def4536ba7d46f97d501c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57398ca0ec944f56b655cac3547e2323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model\n",
    "MODEL_NAME = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"context\"],\n",
    "        batch[\"meaning\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove non-tensor columns\n",
    "for col in [\"context\", \"meaning\", \"stdev\", \"group_id\", \"sample_id\"]:\n",
    "    if col in tokenized[\"train\"].column_names:\n",
    "        tokenized = tokenized.remove_columns(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "38206fc8ff324b8fbe231366d2e139f0",
      "9b1bf089885a4e2e8331fe74cb2b1d80",
      "c883eb4025054dbe9b0da9f1038aecd6",
      "495cbb65f48942f6be1008d5b744f6d2",
      "76f234773f55450086310c4f1acefe4b",
      "ab926003be1d497f8032a69b43d83391",
      "bf0873379f45479682a6735994734b56",
      "3b5de50df58b4bd097b0dbb9d295eb6c",
      "c100ce4aca104bfcb0a1bca0a41f10ae",
      "136909a1fb81454087a05585c714d248",
      "097d732e4590410dbd2c28fba16b6249"
     ]
    },
    "id": "ejXGzR6ukYbi",
    "outputId": "1a94508b-0b78-445a-8f61-0ae05ee54472"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38206fc8ff324b8fbe231366d2e139f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnvkJpNkko0v",
    "outputId": "92ee60b8-4fc9-48d5-a3f1-bbcc3de83fd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2087916016.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr),\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= None,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"], \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "pesEh2dLkrbr",
    "outputId": "507e5a98-18cf-4350-a130-cb56dcbe6115"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanand\u001b[0m (\u001b[33mbanand-university-of-massachusetts-amherst\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251217_023339-gq5c5hbf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/gq5c5hbf' target=\"_blank\">clean-wildflower-18</a></strong> to <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface' target=\"_blank\">https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/gq5c5hbf' target=\"_blank\">https://wandb.ai/banand-university-of-massachusetts-amherst/huggingface/runs/gq5c5hbf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 01:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.544300</td>\n",
       "      <td>1.402328</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>1.023489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.308200</td>\n",
       "      <td>1.424862</td>\n",
       "      <td>0.045427</td>\n",
       "      <td>1.024829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.326500</td>\n",
       "      <td>1.362300</td>\n",
       "      <td>0.203577</td>\n",
       "      <td>1.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.140900</td>\n",
       "      <td>1.388653</td>\n",
       "      <td>0.314077</td>\n",
       "      <td>0.987746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>1.405425</td>\n",
       "      <td>0.330649</td>\n",
       "      <td>0.967405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>1.491716</td>\n",
       "      <td>0.350595</td>\n",
       "      <td>0.969528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>1.613129</td>\n",
       "      <td>0.355013</td>\n",
       "      <td>1.005506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>1.495106</td>\n",
       "      <td>0.378847</td>\n",
       "      <td>0.968827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>1.509133</td>\n",
       "      <td>0.377789</td>\n",
       "      <td>0.974947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>1.590987</td>\n",
       "      <td>0.381656</td>\n",
       "      <td>1.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1140, training_loss=1.0221399470379477, metrics={'train_runtime': 96.4095, 'train_samples_per_second': 189.193, 'train_steps_per_second': 11.825, 'total_flos': 2399551280087040.0, 'train_loss': 1.0221399470379477, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "n0pke0BBk3Rc",
    "outputId": "abcbd19a-32b9-4e55-cc59-e3510986892e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL EVAL ON DEV (TEST)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Spearman:       0.3817\n",
      "Macro Spearman:        0.3801\n",
      "MAE:                   1.0000\n",
      "Accuracy within stdev: 0.5442\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFINAL EVAL ON DEV (TEST)\")\n",
    "\n",
    "pred = trainer.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred.predictions), 1.0, 5.0)\n",
    "\n",
    "# Global Spearman & MAE \n",
    "global_spearman = spearmanr(dev_labels, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(dev_labels - raw_preds))\n",
    "\n",
    "# Macro-Spearman \n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(dev_groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_sps = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = dev_labels[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "\n",
    "    if np.all(g_true == g_true[0]):\n",
    "        continue\n",
    "\n",
    "    corr = spearmanr(g_true, g_pred).correlation\n",
    "    if not np.isnan(corr):\n",
    "        group_sps.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_sps)) if group_sps else 0.0\n",
    "\n",
    "# Accuracy within stdev \n",
    "errors = np.abs(raw_preds - dev_labels)\n",
    "within = errors <= dev_stdevs\n",
    "acc_stdev = float(np.mean(within))\n",
    "\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within stdev: {acc_stdev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMSTmllck9lq"
   },
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def bootstrap_test_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    global_sps = []\n",
    "    macro_sps = []\n",
    "    maes = []\n",
    "    acc_stdevs = []\n",
    "\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, gid in enumerate(groups):\n",
    "        group_to_indices[gid].append(i)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # ---- Global Spearman ----\n",
    "        rho = spearmanr(bt_true, bt_pred).correlation\n",
    "        global_sps.append(rho)\n",
    "\n",
    "        # ---- MAE ----\n",
    "        maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # ---- Accuracy within stdev ----\n",
    "        acc_stdevs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # ---- Macro Spearman ----\n",
    "        local_group_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_group_map[g].append(i)\n",
    "\n",
    "        group_corrs = []\n",
    "        for g, idxs in local_group_map.items():\n",
    "            gt = bt_true[idxs]\n",
    "            gp = bt_pred[idxs]\n",
    "\n",
    "            if np.all(gt == gt[0]):\n",
    "                continue\n",
    "\n",
    "            c = spearmanr(gt, gp).correlation\n",
    "            if not np.isnan(c):\n",
    "                group_corrs.append(c)\n",
    "\n",
    "        if group_corrs:\n",
    "            macro_sps.append(np.mean(group_corrs))\n",
    "        else:\n",
    "            macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"global_spearman\": summarize(global_sps),\n",
    "        \"macro_spearman\": summarize(macro_sps),\n",
    "        \"mae\": summarize(maes),\n",
    "        \"acc_within_stdev\": summarize(acc_stdevs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq6j7Qk0k-PE",
    "outputId": "23f62e8d-2599-46f9-8728-d65c785c6ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOOTSTRAP RESULTS (TEST SET)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3268535183.py:52: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  c = spearmanr(gt, gp).correlation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_spearman     : 0.3811 [0.3100, 0.4476]\n",
      "macro_spearman      : 0.3462 [0.2512, 0.4370]\n",
      "mae                 : 1.0002 [0.9424, 1.0649]\n",
      "acc_within_stdev    : 0.5443 [0.5068, 0.5834]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "\n",
    "bootstrap_results = bootstrap_test_metrics(\n",
    "    y_true=dev_labels,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=dev_stdevs,\n",
    "    groups=dev_groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_results.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}