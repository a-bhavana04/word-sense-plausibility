{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nZ8FTF2ijVR",
    "outputId": "96e5f057-93ff-4b39-c5f7-a61f8f7f038d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE9P_zjlipNk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVexX7mAirVQ"
   },
   "outputs": [],
   "source": [
    "#seeding for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEGC_AtAitan"
   },
   "outputs": [],
   "source": [
    "TRAIN_JSON_PATH = \"/content/drive/MyDrive/nlp/train.json\"\n",
    "DEV_JSON_PATH   = \"/content/drive/MyDrive/nlp/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75KVWVn8iv0f"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOZDnaI-ix0G"
   },
   "outputs": [],
   "source": [
    "def load_json_records(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "train_records = load_json_records(TRAIN_JSON_PATH)\n",
    "dev_records   = load_json_records(DEV_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IqnlFYEizmu"
   },
   "outputs": [],
   "source": [
    "#building input examples\n",
    "def build_examples(records):\n",
    "    # flattening nested lists so every item is a dict\n",
    "    def flatten(xs):\n",
    "        for x in xs:\n",
    "            if isinstance(x, list):\n",
    "                yield from flatten(x)\n",
    "            else:\n",
    "                yield x\n",
    "\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "\n",
    "    records = list(flatten(records))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for r in records:\n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "\n",
    "        pre = (r.get(\"precontext\") or \"\").strip()\n",
    "        sent = (r.get(\"sentence\") or \"\").strip()\n",
    "        end = (r.get(\"ending\") or \"\").strip()\n",
    "        meaning = (r.get(\"judged_meaning\") or \"\").strip()\n",
    "\n",
    "        meaning_txt = (\n",
    "            \"Meaning (intended definition):\\n\"\n",
    "            f\"{meaning}\"\n",
    "        )\n",
    "\n",
    "        story_parts = [pre, sent]\n",
    "        if end:\n",
    "            story_parts.append(end)\n",
    "\n",
    "        story_txt = \"Story:\\n\" + \"\\n\".join(story_parts)\n",
    "\n",
    "        ex_sent = (r.get(\"example_sentence\") or \"\").strip()\n",
    "        if ex_sent:\n",
    "            story_txt += f\"\\nExample sentence: {ex_sent}\"\n",
    "\n",
    "        label = float(r.get(\"average\", 0.0))\n",
    "\n",
    "        gid = f\"{r.get('homonym', '')}||{sent}\"\n",
    "\n",
    "        out.append({\n",
    "            \"context\": story_txt,\n",
    "            \"meaning\": meaning_txt,\n",
    "            \"label\": label,\n",
    "            \"stdev\": float(r.get(\"stdev\", 0)),\n",
    "            \"group_id\": gid,\n",
    "            \"choices\": r.get(\"choices\"),\n",
    "            \"nonsensical\": r.get(\"nonsensical\"),\n",
    "            \"sample_id\": r.get(\"sample_id\")\n",
    "        })\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUOeVXjIi2J8"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "train_examples = build_examples(train_records)\n",
    "dev_examples   = build_examples(dev_records)\n",
    "\n",
    "train_df = pd.DataFrame(train_examples)\n",
    "dev_df   = pd.DataFrame(dev_examples)\n",
    "\n",
    "dev_labels = dev_df[\"label\"].to_numpy(float)\n",
    "dev_stdevs = dev_df[\"stdev\"].to_numpy(float)\n",
    "dev_groups = dev_df[\"group_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiGBK2vRi_MV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting original train_df into 80/20\n",
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# building HF DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df_split, preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df_split, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(dev_df, preserve_index=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372,
     "referenced_widgets": [
      "50ca55e0552e4612bf15520b728e4fe2",
      "3a3871da16494680ba14e003f2715338",
      "7a44cccfdace4e268ece429838ac3fa2",
      "bf8daa2370ca4bac9aa7d4190ac207e7",
      "694c18656b1f459f9cf0f12314609954",
      "d04991992de74bcdbaab2ecbdbe85d9e",
      "247207b3d5ff4718838225618d3f0666",
      "d5aae64430684ccfbc004043c6480d9d",
      "9d4dd83afd0e4d429516b2872c1cbbf0",
      "32a5bae004ea449284325a1dfdd287f4",
      "1c3b50baaca34689adcf7b85ca82b9de",
      "b64a5c9d666d40c1a843cee13994ab1c",
      "25f5c14faa3b4c95a9b49f8b5e939efd",
      "db02c45450b141319a5c58f8a81ca1d4",
      "cf7e9faa677c499fa5110e39ea37ccf1",
      "31682d02bbb34119b52524b6875cab50",
      "db44acaa18fd4924a56da3a259e8282b",
      "7e356642f5fe4af69b9a09a61d38fdcb",
      "3c47981db9f44be3ac0686a607506b22",
      "2156313214614836bbb3b7ac0a4ff147",
      "945bb0617ac041d2b3c37b6bf4b8eecc",
      "1d689571e7dc478b939c068c3dfa085c",
      "0e7ed2d2edaa4f66b075de9d4afffb5e",
      "027284b395a1484ca172dafd79e96206",
      "a0c557024ed1465582f213cd7e023be0",
      "a0effbc8c21c4bcaacd11fc12a1642b0",
      "9d1c73c12832403da4d4a96a1c697d9e",
      "9da6f8d778224a8eb18bbf7d5eecc296",
      "6508cac4d5dd4796bb548faae6cca43c",
      "4c7633bab2b449008facf9cd5ef541a5",
      "a8e82faddffe4330ac89501e177a1b97",
      "36ff2d4cb98847e18c3d938ae1460553",
      "4839d38caadd483a9108c2323155cc84",
      "1e904d1293d54c78a160ce9f9c538deb",
      "5360375e4eae472e838e088fc92f54ff",
      "57c277e3f79444248379dc5db936c62e",
      "b1bbd31055ae4a4588f74098accecd70",
      "bdc8ec4ecb6a48b9857bec7ad546d05f",
      "e63c736d9a494bfb9094d54daaffd2e2",
      "ab74e569ab454c2ab7c42b72abc2a0c8",
      "bc0ad577cb7a482aa948b58e0e97c308",
      "daadc9914a5e468c9ef8e51c764790d5",
      "5a597e5d227b4882ab1d3ce92024d7ce",
      "a8e106464e174b18b88dd9f45143036c",
      "8adb06c6df27497e9be1c3a9df812795",
      "64814dfdc8ea438eb6fb854c86cc5645",
      "5d8a52ad2af84ed1893f0073407ac096",
      "687c5bc150b542f2b0a9dc598b7622f1",
      "748333e2f5ca4686aa7a5e1cb5769071",
      "69a06e3fae2e411ea029f78cf46dadca",
      "3ec667190e024bb1be672bcd0e237f6d",
      "8458dde28f1346358df09fe0d25bc9ec",
      "b0211617da424ebd9117ca519be5eff5",
      "5575f05947af471b8a4a996e628bbe61",
      "08970a2d06874a47b3a8188e612d2fe1",
      "90cb18fac1514a8683a40c0571df1ab2",
      "d8277e9b89fc434cb35033e125b28d24",
      "b264e92c2f414cd78f25e013006931b4",
      "e267d8d31abe478e870cdfc393b95f21",
      "15c59072fc994be9af2788d636931e8f",
      "58743c1a4e07455da1e38bfaee845ce4",
      "32572bdfd75a4940a49a49ae1cb26687",
      "fdc784ad8c424adbbefba715c06059fd",
      "fe642713bd6d4792a238bd6759096af4",
      "1a4521b786734d89aedbfb8c6845a0ba",
      "6fa345bdf0b0472897f72ab090a193a8"
     ]
    },
    "id": "8GRXwVcxjC5U",
    "outputId": "5ba5a68c-9ba6-42f0-c7d3-227fe0703bff"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"context\"],\n",
    "        batch[\"meaning\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove non-tensor columns\n",
    "for col in [\"context\", \"meaning\", \"stdev\", \"group_id\", \"sample_id\"]:\n",
    "    if col in tokenized[\"train\"].column_names:\n",
    "        tokenized = tokenized.remove_columns(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "9ffa7bf929a042cbb5bfaa4d3621084f",
      "06ff7611cbb24e109be80af7f03a8df3",
      "973fd597dd594609a8e28c1a8c2bc14e",
      "500a0cb4a3304fd9bc08f5331e5162ff",
      "35fe85c7cdb64ce096b0980be556982e",
      "42918bc1485b475dbd2aca81f9b8656b",
      "cbb23c7002b1475bacbb9c288ad51d18",
      "67b2125f2597433dbc33398618cfa7f6",
      "14beb95f9ead441fbd2f80836fc8f2c7",
      "52a7bc4e66e34e5cbd7d6acb29079594",
      "610adb0ad49a4621b80ff93894b081f5",
      "73774de937b148b8bedd0819e00878bc",
      "d0079bbcf93e446da761edd2c5b48011",
      "496c2e845d054a8ebfd9a542194d401f",
      "357c041ae0b24e8bb0a75c14b523fa42",
      "d574c686caa04b2d8fca4f14498dbe78",
      "67c135bc978f43d68cc0db960a16ff3f",
      "fcbfbfebd9b04184b0f1146012b26ab2",
      "e4587d62852a46d9b329348cffc0abb7",
      "70c4fa726889407b82feb0adc08c1f1f",
      "0eb7fc3b4ada47c1b84d95d4c3055b31",
      "b77f59f292b2495f968bd6006976e267"
     ]
    },
    "id": "ejXGzR6ukYbi",
    "outputId": "91b693d5-8883-450f-c4f0-719c90e5396b"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "AnvkJpNkko0v",
    "outputId": "9ec99f3f-5f7e-445f-ae0e-5a5fee13b235"
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.clip(np.squeeze(preds), 1.0, 5.0)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    spearman_corr = spearmanr(labels, preds).correlation\n",
    "    mae = np.mean(np.abs(labels - preds))\n",
    "\n",
    "    return {\n",
    "        \"spearman\": float(spearman_corr),\n",
    "        \"mae\": float(mae),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= None,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"spearman\",\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=20,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],  \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "pesEh2dLkrbr",
    "outputId": "d225460f-5583-4366-f667-d661397a3f59"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "n0pke0BBk3Rc",
    "outputId": "d41e6d51-ecc4-45b7-a577-645509464737"
   },
   "outputs": [],
   "source": [
    "print(\"\\nFINAL EVAL ON DEV (TEST)\")\n",
    "\n",
    "pred = trainer.predict(tokenized[\"test\"])\n",
    "raw_preds = np.clip(np.squeeze(pred.predictions), 1.0, 5.0)\n",
    "\n",
    "# Global Spearman & MAE\n",
    "global_spearman = spearmanr(dev_labels, raw_preds).correlation\n",
    "global_mae = np.mean(np.abs(dev_labels - raw_preds))\n",
    "\n",
    "#  Macro-Spearman\n",
    "group_indices = defaultdict(list)\n",
    "for i, gid in enumerate(dev_groups):\n",
    "    group_indices[gid].append(i)\n",
    "\n",
    "group_sps = []\n",
    "for gid, idxs in group_indices.items():\n",
    "    g_true = dev_labels[idxs]\n",
    "    g_pred = raw_preds[idxs]\n",
    "\n",
    "    if np.all(g_true == g_true[0]):\n",
    "        continue\n",
    "\n",
    "    corr = spearmanr(g_true, g_pred).correlation\n",
    "    if not np.isnan(corr):\n",
    "        group_sps.append(corr)\n",
    "\n",
    "macro_spearman = float(np.mean(group_sps)) if group_sps else 0.0\n",
    "\n",
    "# Accuracy within stdev \n",
    "errors = np.abs(raw_preds - dev_labels)\n",
    "within = errors <= dev_stdevs\n",
    "acc_stdev = float(np.mean(within))\n",
    "\n",
    "print(f\"Global Spearman:       {global_spearman:.4f}\")\n",
    "print(f\"Macro Spearman:        {macro_spearman:.4f}\")\n",
    "print(f\"MAE:                   {global_mae:.4f}\")\n",
    "print(f\"Accuracy within stdev: {acc_stdev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMSTmllck9lq"
   },
   "outputs": [],
   "source": [
    "#bootstrapping\n",
    "def bootstrap_test_metrics(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_stdev,\n",
    "    groups,\n",
    "    n_bootstrap=1000,\n",
    "    seed=42\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "\n",
    "    global_sps = []\n",
    "    macro_sps = []\n",
    "    maes = []\n",
    "    acc_stdevs = []\n",
    "\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, gid in enumerate(groups):\n",
    "        group_to_indices[gid].append(i)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "\n",
    "        bt_true = y_true[idx]\n",
    "        bt_pred = y_pred[idx]\n",
    "        bt_stdev = y_stdev[idx]\n",
    "        bt_groups = [groups[i] for i in idx]\n",
    "\n",
    "        # ---- Global Spearman ----\n",
    "        rho = spearmanr(bt_true, bt_pred).correlation\n",
    "        global_sps.append(rho)\n",
    "\n",
    "        # ---- MAE ----\n",
    "        maes.append(np.mean(np.abs(bt_true - bt_pred)))\n",
    "\n",
    "        # ---- Accuracy within stdev ----\n",
    "        acc_stdevs.append(np.mean(np.abs(bt_true - bt_pred) <= bt_stdev))\n",
    "\n",
    "        # ---- Macro Spearman ----\n",
    "        local_group_map = defaultdict(list)\n",
    "        for i, g in enumerate(bt_groups):\n",
    "            local_group_map[g].append(i)\n",
    "\n",
    "        group_corrs = []\n",
    "        for g, idxs in local_group_map.items():\n",
    "            gt = bt_true[idxs]\n",
    "            gp = bt_pred[idxs]\n",
    "\n",
    "            if np.all(gt == gt[0]):\n",
    "                continue\n",
    "\n",
    "            c = spearmanr(gt, gp).correlation\n",
    "            if not np.isnan(c):\n",
    "                group_corrs.append(c)\n",
    "\n",
    "        if group_corrs:\n",
    "            macro_sps.append(np.mean(group_corrs))\n",
    "        else:\n",
    "            macro_sps.append(np.nan)\n",
    "\n",
    "    def summarize(arr):\n",
    "        arr = np.array(arr, dtype=float)\n",
    "        return {\n",
    "            \"mean\": float(np.nanmean(arr)),\n",
    "            \"ci_low\": float(np.nanpercentile(arr, 2.5)),\n",
    "            \"ci_high\": float(np.nanpercentile(arr, 97.5)),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"global_spearman\": summarize(global_sps),\n",
    "        \"macro_spearman\": summarize(macro_sps),\n",
    "        \"mae\": summarize(maes),\n",
    "        \"acc_within_stdev\": summarize(acc_stdevs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq6j7Qk0k-PE",
    "outputId": "3ba3d05c-ae4e-476e-f912-594aeaf69a70"
   },
   "outputs": [],
   "source": [
    "print(\"\\nBOOTSTRAP RESULTS (TEST SET)\")\n",
    "\n",
    "bootstrap_results = bootstrap_test_metrics(\n",
    "    y_true=dev_labels,\n",
    "    y_pred=raw_preds,\n",
    "    y_stdev=dev_stdevs,\n",
    "    groups=dev_groups,\n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "for metric, stats in bootstrap_results.items():\n",
    "    print(\n",
    "        f\"{metric:20s}: \"\n",
    "        f\"{stats['mean']:.4f} \"\n",
    "        f\"[{stats['ci_low']:.4f}, {stats['ci_high']:.4f}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
